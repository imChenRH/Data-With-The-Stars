# 模型建立模块

> **版本**: v2.0（更新于2026-01-30）  
> **适用题目**: MCM 2026 Problem C - Dancing with the Stars  
> **先导要求**: 
> - 问题一双方案：约束优化+先验正则化、贝叶斯+狄利克雷+拒绝采样
> - 问题二创新：Kendall τ + Bootstrap敏感性分析
> - 问题三双方案：混合效应模型、XGBoost+SHAP
> - 问题四创新：NSGA-II + 帕累托前沿

---

## 目录

1. [问题一：粉丝投票估算模型建立](#一问题一粉丝投票估算模型建立)
2. [问题二：投票方法比较模型建立](#二问题二投票方法比较模型建立)
3. [问题三：影响因素分析模型建立](#三问题三影响因素分析模型建立)
4. [问题四：新投票系统设计模型建立](#四问题四新投票系统设计模型建立)
5. [符号统一说明](#五符号统一说明)

---

## 一、问题一：粉丝投票估算模型建立

### 1.1 方案一：约束优化模型

#### 1.1.1 变量/特征定义

| 变量符号 | 变量名称 | 类型 | 字段含义 | 处理方式 | 分析意义 |
|---------|---------|------|---------|---------|---------|
| $J_{i,w}$ | 评委总分 | 连续(原始) | 选手i在第w周的评委总分 | 直接使用/归一化 | 反映舞蹈技术水平 |
| $V_{i,w}$ | 粉丝投票比例 | 连续(目标) | 选手i在第w周的粉丝投票占比 | **待估算** | 逆向推断目标变量 |
| $E_{i,w}$ | 淘汰标记 | 离散(原始) | 选手i在第w周是否被淘汰 | 0/1编码 | 约束条件验证 |
| $n_w$ | 参赛人数 | 离散(衍生) | 第w周参赛选手数量 | 统计计算 | 动态约束边界 |
| $R^J_{i,w}$ | 评委排名 | 离散(衍生) | 基于评委分的周内排名 | 降序排序 | 排名制合并依据 |
| $R^V_{i,w}$ | 粉丝排名 | 离散(目标) | 基于粉丝投票的周内排名 | **待推断** | 排名制合并依据 |

#### 1.1.2 假设条件

| 假设编号 | 假设内容 | 合理性说明 |
|---------|---------|-----------|
| **A1** | 粉丝投票比例服从单纯形约束：$\sum_{i=1}^{n_w} V_{i,w} = 1$，$V_{i,w} \geq 0$ | 投票为零和博弈，总票数固定，符合比例分配逻辑 |
| **A2** | 淘汰者为综合得分最低者（无平局） | 题目规则明确，数据中未出现平局淘汰记录 |
| **A3** | 评委评分与粉丝投票相互独立 | 评委打分在投票前公布，但投票已开始，假设独立可简化模型 |
| **A4** | 同一季内粉丝投票分布相对稳定 | 粉丝基础短期内不会剧烈变化，允许跨周信息借鉴 |

#### 1.1.3 模型公式推导

**Step 1: 定义综合得分函数**

根据投票规则阶段，定义综合得分：

- **排名制（S1-2, S28-34）**:
$$C_{i,w} = R^J_{i,w} + R^V_{i,w} \tag{1}$$

- **百分比制（S3-27）**:
$$C_{i,w} = \frac{J_{i,w}}{\sum_{j=1}^{n_w} J_{j,w}} + V_{i,w} \tag{2}$$

**Step 2: 淘汰约束条件**

设第w周被淘汰选手集合为 $\mathcal{E}_w$，则：
$$\forall e \in \mathcal{E}_w, \forall i \notin \mathcal{E}_w: C_{e,w} < C_{i,w} \tag{3}$$

即淘汰者的综合得分严格低于所有存活者。

**Step 3: 约束优化目标函数**

引入正则化项，构建优化问题：

$$\min_{\{V_{i,w}\}} \sum_{w=1}^{W} \sum_{i=1}^{n_w} \left( V_{i,w} - \bar{V}_i \right)^2 + \lambda \cdot \text{Entropy}(V_w) \tag{4}$$

**约束条件**:
- 单纯形约束: $\sum_{i=1}^{n_w} V_{i,w} = 1$, $V_{i,w} \geq 0$
- 淘汰约束: 式(3)对所有周成立
- 边界约束: $V_{i,w} \in [0.01, 0.50]$（经验边界）

**Step 4: 求解方法**

采用序列二次规划(SQP)或内点法求解：

```
初始化: V⁰ ~ Uniform(1/n)
迭代:
  计算梯度: ∇L = 2(V - V̄) - λ∇H(V)
  更新: V^(k+1) = V^k - α·∇L
  投影到可行域: V = Project(V, Constraints)
终止: ||V^(k+1) - V^k|| < ε
```

#### 1.1.4 建模流程图

```
┌─────────────────────────────────────────────────────────────────┐
│                      约束优化模型建模流程                        │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  [数据输入] ─────────────────────────────────────────────────►  │
│      │                                                          │
│      ▼                                                          │
│  ┌─────────────────┐                                            │
│  │ 1. 数据预处理   │                                            │
│  │ • 识别规则阶段  │  输出: rule_phase ∈ {1,2,3}               │
│  │ • 提取淘汰信息  │  输出: elimination_dict                    │
│  │ • 计算评委排名  │  输出: judge_ranks                         │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 2. 约束构建     │  ⚠️ 关键节点：验证约束可行性               │
│  │ • 单纯形约束    │     若无可行解 → 放松边界约束              │
│  │ • 淘汰约束      │                                            │
│  │ • 边界约束      │  输出: constraint_matrix A, b              │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 3. 优化求解     │                                            │
│  │ • 初始化V⁰     │                                            │
│  │ • SQP迭代      │  ⚠️ 监控收敛性：若不收敛 → 调整λ           │
│  │ • 投影到可行域  │  输出: V_optimal, convergence_curve        │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 4. 结果验证     │                                            │
│  │ • 约束满足检查  │  输出: constraint_satisfaction_rate        │
│  │ • 淘汰一致性    │  输出: elimination_accuracy                │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  [输出: 粉丝投票估算值 V̂_{i,w}]                                 │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

### 1.2 方案二：贝叶斯MCMC + 狄利克雷 + 拒绝采样模型

> **模型选择原理**：狄利克雷分布是单纯形上的共轭先验，与投票比例的数学结构天然匹配。拒绝采样（而非MH算法）更直接，当约束域占比合理时效率更高。

#### 1.2.1 变量/特征定义

| 变量符号 | 变量名称 | 类型 | 字段含义 | 处理方式 | 分析意义 |
|---------|---------|------|---------|---------|---------|
| $\boldsymbol{V}_w$ | 投票向量 | 连续(目标) | 第w周所有选手投票比例 | 狄利克雷采样 | 联合估算对象 |
| $\boldsymbol{\alpha}_w$ | 狄利克雷参数 | 连续(先验) | 投票分布的集中度参数 | 先验设定/自适应 | 控制不确定性 |
| $\mathcal{D}$ | 观测数据 | - | 评委分+淘汰结果 | 似然计算 | 后验更新依据 |
| $\mathcal{A}_w$ | 约束可行域 | 集合 | 满足淘汰约束的区域 | 几何定义 | 拒绝采样判据 |

#### 1.2.2 假设条件

| 假设编号 | 假设内容 | 合理性说明 |
|---------|---------|-----------|
| **B1** | 粉丝投票服从狄利克雷分布：$\boldsymbol{V}_w \sim \text{Dir}(\boldsymbol{\alpha}_w)$ | 狄利克雷是单纯形上的共轭先验，数学形式自然匹配投票比例（和为1，非负） |
| **B2** | 先验参数可选均匀或信息性：$\alpha_i = 1$（均匀）或 $\alpha_i \propto J_i$（信息性） | 无强先验时用均匀；有理由相信高分选手获票更多时用信息性先验 |
| **B3** | 淘汰事件为硬约束（似然为0-1指示函数） | 观测到的淘汰结果提供确定性信息，不存在观测噪声 |
| **B4** | 约束可行域体积占比>1%，拒绝采样可行 | 若拒绝率过高（>99%），切换到切片采样或HMC |

#### 1.2.3 模型公式推导

**Step 1: 定义先验分布**

**均匀先验**（最大熵，信息量最少）：
$$\boldsymbol{V}_w \sim \text{Dirichlet}(1, 1, ..., 1) \tag{5}$$

**信息性先验**（假设粉丝倾向投高分选手）：
$$\boldsymbol{V}_w \sim \text{Dirichlet}(\alpha \cdot \tilde{J}_1, \alpha \cdot \tilde{J}_2, ..., \alpha \cdot \tilde{J}_{n_w}) \tag{5'}$$

其中 $\tilde{J}_i = J_i / \sum_j J_j$ 为归一化评委分，$\alpha > 0$ 控制先验强度。

**狄利克雷分布的概率密度**：
$$p(\boldsymbol{V} | \boldsymbol{\alpha}) = \frac{\Gamma(\sum_i \alpha_i)}{\prod_i \Gamma(\alpha_i)} \prod_{i=1}^{n} V_i^{\alpha_i - 1} \tag{6}$$

**Step 2: 定义约束可行域**

设第w周被淘汰者为选手 $L$，则可行域为：

**百分比制（S3-27）**：
$$\mathcal{A}_w = \left\{ \boldsymbol{V} : \frac{J_L}{\sum_j J_j} + V_L < \frac{J_k}{\sum_j J_j} + V_k, \forall k \neq L \right\} \tag{7a}$$

**排名制（S1-2, S28-34）**：
$$\mathcal{A}_w = \left\{ \boldsymbol{V} : \text{Rank}(J_L) + \text{Rank}(V_L) > \text{Rank}(J_k) + \text{Rank}(V_k), \forall k \neq L \right\} \tag{7b}$$

**Step 3: 拒绝采样算法**

```python
# 拒绝采样伪代码
def rejection_sampling(alpha, n_samples, constraint_fn):
    """
    从约束后验分布采样
    
    Parameters:
    -----------
    alpha : array, 狄利克雷参数
    n_samples : int, 所需样本数
    constraint_fn : callable, 约束检验函数
    
    Returns:
    --------
    samples : array [n_samples, n], 后验样本
    acceptance_rate : float, 接受率（诊断指标）
    """
    samples = []
    n_proposed = 0
    
    while len(samples) < n_samples:
        # Step 1: 从先验采样
        V_proposal = np.random.dirichlet(alpha)
        n_proposed += 1
        
        # Step 2: 检验约束
        if constraint_fn(V_proposal):
            # 接受样本
            samples.append(V_proposal)
    
    acceptance_rate = n_samples / n_proposed
    
    # 诊断: 若接受率<1%, 发出警告
    if acceptance_rate < 0.01:
        warnings.warn("Acceptance rate too low! Consider slice sampling.")
    
    return np.array(samples), acceptance_rate
```

**Step 4: 自适应先验调整**

若拒绝率过高，可采用**自适应先验**：

1. 先用均匀先验采样少量样本
2. 计算接受样本的均值 $\bar{V}$
3. 设置信息性先验 $\alpha_i = c \cdot \bar{V}_i$（$c$ 为集中度参数）
4. 重新采样

**Step 5: 后验统计量**

- **点估计**：后验均值 $\hat{V}_{i,w} = \mathbb{E}[V_{i,w} | \mathcal{D}] = \frac{1}{N}\sum_{s=1}^N V_i^{(s)}$
- **不确定性**：后验标准差 $\text{SD}[V_{i,w} | \mathcal{D}]$
- **置信区间**：95% HPD（Highest Posterior Density）区间
- **确定性指标**：香农熵 $H = -\sum_i \hat{V}_i \log \hat{V}_i$（熵越低，分布越集中）

#### 1.2.4 建模流程图

```
┌─────────────────────────────────────────────────────────────────┐
│              贝叶斯+狄利克雷+拒绝采样模型建模流程                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  [数据输入: J, 淘汰结果] ────────────────────────────────────►  │
│      │                                                          │
│      ▼                                                          │
│  ┌─────────────────┐                                            │
│  │ 1. 先验设定     │                                            │
│  │ • 均匀: α=(1,..,1)│                                          │
│  │ • 信息性: α∝J   │  选择依据: 是否有先验信念                  │
│  │ • 集中度参数c   │  输出: prior_params                        │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 2. 约束域定义   │                                            │
│  │ • 识别规则阶段  │  输出: rule_phase ∈ {rank, percentage}     │
│  │ • 构建约束函数  │  输出: constraint_fn(V) → bool             │
│  │ • 估算可行域比例│  ⚠️ 若<1% → 切换采样方法                   │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 3. 拒绝采样     │                                            │
│  │ • 目标样本:5000 │                                            │
│  │ • 监控接受率    │  ⚠️ 若接受率<1% → 自适应调整先验           │
│  │ • 并行采样优化  │  输出: posterior_samples [5000, n]         │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 4. 收敛诊断     │                                            │
│  │ • 有效样本量ESS │  ⚠️ 要求: ESS > 1000                       │
│  │ • 自相关分析    │  输出: diagnostics_report                  │
│  │ • 轨迹图检查    │  输出: trace_plots                         │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 5. 后验分析     │                                            │
│  │ • 点估计（均值）│  输出: V_hat [n]                           │
│  │ • 95% HPD区间   │  输出: CI_95 [n, 2]                        │
│  │ • 香农熵（确定性│  输出: entropy (标量)                      │
│  │ • 后验分布可视化│  输出: posterior_plots                     │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 6. 一致性验证   │                                            │
│  │ • 约束满足率    │  要求: 100%（拒绝采样保证）                │
│  │ • 淘汰预测准确率│  输出: elimination_accuracy                │
│  │ • 与约束优化对比│  输出: method_comparison                   │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  [输出: 后验分布P(V|D), 点估计V̂, 置信区间CI, 确定性指标H]       │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

#### 1.2.5 方案一vs方案二对比

| 对比维度 | 约束优化+正则化 | 贝叶斯+狄利克雷+拒绝采样 |
|---------|----------------|-------------------------|
| **输出类型** | 点估计 | 完整后验分布 |
| **不确定性** | 无（或需二阶方法） | 自然给出置信区间 |
| **计算效率** | 高（凸优化） | 中等（取决于接受率） |
| **先验融合** | 通过目标函数 | 通过狄利克雷参数 |
| **约束处理** | 严格满足 | 严格满足（拒绝采样保证） |
| **适用场景** | 快速获取点估计 | 需要不确定性量化 |
| **美赛论文** | 简洁，易推导 | 贝叶斯框架，创新性强 |

---

## 二、问题二：投票方法比较模型建立（创新方案）

### 2.1 Kendall τ + Bootstrap敏感性分析模型

> **模型选择原理**：排名制与百分比制的本质区别在于「排名保序性」。Kendall τ系数能精确量化两种方法产生的排名一致性，而Bootstrap可以传播问题一估算的不确定性。

#### 2.1.1 变量/特征定义

| 变量符号 | 变量名称 | 类型 | 字段含义 | 处理方式 | 分析意义 |
|---------|---------|------|---------|---------|---------|
| $\hat{V}_{i,w}$ | 估算投票比例 | 连续(输入) | 问题一估算结果 | 直接使用 | 反事实模拟输入 |
| $R^{rank}_{i,w}$ | 排名制最终排名 | 离散(衍生) | 基于排名合并的排序 | 计算衍生 | 方法一输出 |
| $R^{pct}_{i,w}$ | 百分比制最终排名 | 离散(衍生) | 基于百分比合并的排序 | 计算衍生 | 方法二输出 |
| $\tau_w$ | Kendall τ系数 | 连续(衍生) | 两种排名的一致性 | 统计计算 | **核心比较指标** |
| $O^{obs}_w$ | 实际淘汰结果 | 离散(原始) | 历史真实淘汰记录 | 编码为选手ID | 对照基准 |
| $O^{cf}_w$ | 反事实淘汰结果 | 离散(衍生) | 假设另一规则的淘汰 | 模拟计算 | 规则差异量化 |
| $\Delta_w$ | 结果差异指标 | 离散(衍生) | $\mathbb{1}[O^{obs}_w \neq O^{cf}_w]$ | 0/1编码 | 规则影响度 |

#### 2.1.2 假设条件

| 假设编号 | 假设内容 | 合理性说明 |
|---------|---------|-----------|
| **C1** | 粉丝投票不因规则变化而改变 | 投票行为主要由粉丝偏好驱动，短期内规则感知有限；社会选择理论中的"独立于不相关选项" |
| **C2** | 估算的投票比例具有足够精度 | 问题一模型验证通过后（约束满足率>95%），可作为反事实输入 |
| **C3** | 规则变化仅影响合并方式，不影响评委打分 | 评委独立评分在投票前完成，制度设计保证独立性 |
| **C4** | Kendall τ适用于离散排名比较 | τ系数专为排名数据设计，对并列处理有明确定义 |

#### 2.1.3 模型公式推导

**Step 1: 两种合并方法的数学定义**

**排名制（Rank-based）合并**：
$$C^{rank}_{i,w} = \text{Rank}(J_{i,w}) + \text{Rank}(\hat{V}_{i,w}) \tag{8}$$

其中 $\text{Rank}(\cdot)$ 为降序排名（最高分排第1）。

**百分比制（Percentage-based）合并**：
$$C^{pct}_{i,w} = \frac{J_{i,w}}{\sum_{j=1}^{n_w} J_{j,w}} + \hat{V}_{i,w} \tag{9}$$

由此得到两种最终排名：
$$R^{rank}_{i,w} = \text{Rank}(C^{rank}_{i,w}), \quad R^{pct}_{i,w} = \text{Rank}(C^{pct}_{i,w})$$

**Step 2: Kendall τ系数计算**

Kendall τ-b系数（处理并列）：
$$\tau_b = \frac{n_c - n_d}{\sqrt{(n_0 - n_1)(n_0 - n_2)}} \tag{10}$$

其中：
- $n_c$ = 一致对数（两种排名同向）
- $n_d$ = 不一致对数（两种排名逆向）
- $n_0 = \frac{n(n-1)}{2}$ = 总对数
- $n_1$ = 第一排名的并列修正项
- $n_2$ = 第二排名的并列修正项

**统计意义**：
- $\tau = 1$：两种方法完全一致
- $\tau = 0$：两种方法无关联
- $\tau = -1$：两种方法完全相反

**Step 3: Bootstrap不确定性传播**

由于 $\hat{V}$ 存在估算误差，采用Bootstrap量化τ的不确定性：

```
For b = 1 to B (B=2000):
    V^{(b)} ~ P(V|D)  # 从问题一后验采样
    计算 R^{rank,(b)}  # 排名制排名
    计算 R^{pct,(b)}   # 百分比制排名
    计算 τ^{(b)}       # Kendall τ系数
    计算 O^{cf,(b)}_w  # 反事实淘汰
    计算 Δ^{(b)}_w    # 差异指标
End

输出:
- τ的点估计: τ̂ = mean(τ^{(b)})
- τ的95%置信区间: [τ_{2.5%}, τ_{97.5%}]
- 规则差异概率: P(差异) = mean(Δ^{(b)})
```

**Step 4: 统计检验**

**Kendall τ显著性检验**（H₀: τ = 0）：
$$z = \frac{3\tau\sqrt{n(n-1)}}{\sqrt{2(2n+5)}} \tag{11}$$

在大样本下 $z \sim N(0,1)$。

**McNemar检验**（H₀: 两种方法淘汰结果无差异）：
$$\chi^2 = \frac{(b-c)^2}{b+c} \tag{12}$$

其中 $b$ = 仅方法1淘汰的次数，$c$ = 仅方法2淘汰的次数。

**Step 5: 争议案例深度分析**

对于题目点名的争议案例（Jerry Rice S2、Billy Ray Cyrus S14、Bristol Palin S11、Bobby Bones S27）：

**争议得分计算**：
$$\text{Controversy Score} = P(O^{obs} \neq O^{cf}) \cdot |\text{Rank}^{obs} - \text{Rank}^{cf}| \cdot (1 - |\tau_w|) \tag{13}$$

其中 $(1 - |\tau_w|)$ 反映该周两种方法的分歧程度。

#### 2.1.4 建模流程图

```
┌─────────────────────────────────────────────────────────────────┐
│            Kendall τ + Bootstrap敏感性分析建模流程               │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  [问题一输出: P(V|D)] ────────────────────────────────────────► │
│      │                                                          │
│      ▼                                                          │
│  ┌─────────────────┐                                            │
│  │ 1. Bootstrap采样│                                            │
│  │ • 采样B=2000次  │  输出: V_samples[B, n, W]                  │
│  │ • 保证MCMC收敛  │  ⚠️ 验证: ESS > 1000                       │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 2. 双方法排名   │                                            │
│  │ • 排名制合并    │  输出: R_rank_samples[B, n, W]             │
│  │ • 百分比制合并  │  输出: R_pct_samples[B, n, W]              │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 3. Kendall τ计算│                                            │
│  │ • 每周τ_w计算   │  输出: tau_weekly[W]                       │
│  │ • τ的Bootstrap CI│ 输出: tau_ci_95                           │
│  │ • 显著性检验    │  输出: z_stat, p_value                     │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────────────────────────────────────────────────┐│
│  │ 4. 规则差异分析                                              ││
│  │ ┌───────────────┐  ┌───────────────┐  ┌───────────────────┐ ││
│  │ │ 反事实淘汰   │  │ McNemar检验  │  │ 差异概率分布     │ ││
│  │ │ O_cf计算     │→ │ χ²统计量    │→ │ P(O_obs≠O_cf)   │ ││
│  │ └───────────────┘  └───────────────┘  └───────────────────┘ ││
│  │ 输出: O_cf_samples, chi2_stat, p_diff                       ││
│  └─────────────────────────────────────────────────────────────┘│
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 5. 争议案例分析 │  ⚠️ 重点关注4个点名案例                    │
│  │ • Jerry Rice    │  S2: 排名制，评委3名（观众抗议）           │
│  │ • Billy Ray Cyrus│ S14: 百分比制，排名3但淘汰（异常）        │
│  │ • Bristol Palin │  S11: 百分比制，低分高存活（粉丝效应）     │
│  │ • Bobby Bones   │  S27: 百分比制，争议冠军                   │
│  │ • 争议得分计算  │  输出: controversy_report                  │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 6. 跨季节对比   │                                            │
│  │ • S1-2 vs S3-27 │  输出: era_comparison                      │
│  │   vs S28-34     │                                            │
│  │ • τ趋势可视化   │  输出: tau_trend_plot                      │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  [输出: τ分布, 规则差异概率, 置信区间, 争议案例报告, 结论]      │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

#### 2.1.5 预期结论框架

根据模型输出，可得出以下类型结论：

| 分析维度 | 若τ接近1 | 若τ显著<1 |
|---------|---------|-----------|
| **方法一致性** | 两种方法结果高度一致，差异主要在边缘排名 | 两种方法产生显著不同排名 |
| **对观众友好度** | 无明显差异，选择任一方法均可 | 百分比制对高粉丝选手更友好（需验证） |
| **争议案例归因** | 争议主要源于粉丝投票估算不确定性 | 争议确实源于规则本身差异 |
| **制度建议** | 可恢复排名制（更简单） | 需权衡简单性与粉丝影响力 |

---

## 三、问题三：影响因素分析模型建立

### 3.1 方案一：线性混合效应模型(LMEM)

#### 3.1.1 变量/特征定义

| 变量符号 | 变量名称 | 类型 | 字段含义 | 处理方式 | 分析意义 |
|---------|---------|------|---------|---------|---------|
| $Y_{i,w}$ | 响应变量 | 连续(目标) | 评委总分或存活周数 | 直接使用 | 表现度量 |
| $\text{Age}_i$ | 年龄 | 连续(原始) | 参赛时年龄 | 标准化 | 体能/经验代理 |
| $\text{Industry}_i$ | 行业 | 离散(原始) | 名人职业类别 | One-Hot编码 | 粉丝基础代理 |
| $\text{Gender}_i$ | 性别 | 离散(原始) | 男/女 | 0/1编码 | 控制变量 |
| $\text{Pro}_i$ | 专业舞伴 | 离散(原始) | 配对舞伴ID | **随机效应** | 舞伴影响量化 |
| $\text{Season}_i$ | 季数 | 离散(原始) | 参赛季编号 | **随机效应** | 时间趋势控制 |

#### 3.1.2 假设条件

| 假设编号 | 假设内容 | 合理性说明 |
|---------|---------|-----------|
| **D1** | 随机效应服从正态分布：$b_{\text{Pro}} \sim N(0, \sigma^2_{\text{Pro}})$ | 标准混合效应模型假设，便于参数估计 |
| **D2** | 残差独立同分布：$\epsilon \sim N(0, \sigma^2)$ | 同一选手跨周数据通过随机效应建模关联 |
| **D3** | 固定效应与随机效应正交 | 设计矩阵构建时验证 |

#### 3.1.3 模型公式推导

**Step 1: 混合效应模型公式**

$$Y_{i,w} = \underbrace{\beta_0 + \beta_1 \cdot \text{Age}_i + \sum_k \beta_k \cdot \text{Industry}_{ik}}_{\text{固定效应}} + \underbrace{b_{\text{Pro}(i)} + b_{\text{Season}(i)}}_{\text{随机效应}} + \epsilon_{i,w} \tag{11}$$

**Step 2: 方差分量估计**

总方差分解：
$$\text{Var}(Y) = \sigma^2_{\text{Pro}} + \sigma^2_{\text{Season}} + \sigma^2_\epsilon \tag{12}$$

舞伴解释方差比（ICC）：
$$\text{ICC}_{\text{Pro}} = \frac{\sigma^2_{\text{Pro}}}{\sigma^2_{\text{Pro}} + \sigma^2_{\text{Season}} + \sigma^2_\epsilon} \tag{13}$$

**Step 3: 参数估计（REML）**

采用限制最大似然估计：
$$\ell_{\text{REML}}(\theta) = -\frac{1}{2} \left[ \log|V| + \log|X'V^{-1}X| + (Y-X\hat{\beta})'V^{-1}(Y-X\hat{\beta}) \right] \tag{14}$$

#### 3.1.4 建模流程图

```
┌─────────────────────────────────────────────────────────────────┐
│                    LMEM混合效应模型建模流程                      │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  [预处理数据] ────────────────────────────────────────────────► │
│      │                                                          │
│      ▼                                                          │
│  ┌─────────────────┐                                            │
│  │ 1. 特征工程     │                                            │
│  │ • 年龄标准化    │                                            │
│  │ • 行业One-Hot   │  ⚠️ 检查多重共线性: VIF < 5               │
│  │ • 舞伴编码      │  输出: design_matrix X, Z                  │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 2. 模型拟合     │                                            │
│  │ • REML估计      │                                            │
│  │ • 方差分量计算  │  输出: beta_hat, sigma_estimates           │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 3. 显著性检验   │                                            │
│  │ • 固定效应t检验 │  输出: p_values_fixed                      │
│  │ • 随机效应LRT   │  输出: p_values_random                     │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 4. ICC计算      │                                            │
│  │ • 舞伴ICC       │  输出: ICC_pro (舞伴解释比例)              │
│  │ • 季节ICC       │  输出: ICC_season                          │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  [输出: 效应系数, 显著性, 方差分解]                             │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

### 3.2 方案二：XGBoost + SHAP可解释性模型

#### 3.2.1 变量/特征定义

| 变量符号 | 变量名称 | 类型 | 字段含义 | 处理方式 | 分析意义 |
|---------|---------|------|---------|---------|---------|
| $\mathbf{X}_i$ | 特征向量 | 混合(输入) | 所有候选特征 | 编码+标准化 | 模型输入 |
| $Y_i$ | 存活周数 | 连续(目标) | 参赛持续周数 | 直接使用 | 预测目标 |
| $\phi_j$ | SHAP值 | 连续(衍生) | 特征j的边际贡献 | SHAP计算 | 特征重要性 |

#### 3.2.2 假设条件

| 假设编号 | 假设内容 | 合理性说明 |
|---------|---------|-----------|
| **E1** | 特征与目标存在非线性关系 | 树模型自动捕捉，无需预设函数形式 |
| **E2** | SHAP值具有加性分解性质 | Shapley值的数学性质保证 |
| **E3** | 训练数据代表总体分布 | 34季数据覆盖足够时间跨度 |

#### 3.2.3 模型公式推导

**Step 1: XGBoost目标函数**

$$\mathcal{L}(\theta) = \sum_{i=1}^n L(y_i, \hat{y}_i) + \sum_{k=1}^K \Omega(f_k) \tag{15}$$

其中正则化项：
$$\Omega(f) = \gamma T + \frac{1}{2}\lambda \sum_{j=1}^T w_j^2 \tag{16}$$

**Step 2: SHAP值计算**

基于Shapley值的特征贡献：
$$\phi_j = \sum_{S \subseteq N \setminus \{j\}} \frac{|S|!(|N|-|S|-1)!}{|N|!} [f(S \cup \{j\}) - f(S)] \tag{17}$$

**Step 3: 特征重要性排序**

全局重要性：
$$\text{Importance}_j = \frac{1}{n} \sum_{i=1}^n |\phi_j^{(i)}| \tag{18}$$

#### 3.2.4 建模流程图

```
┌─────────────────────────────────────────────────────────────────┐
│                  XGBoost + SHAP建模流程                          │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  [特征矩阵] ──────────────────────────────────────────────────► │
│      │                                                          │
│      ▼                                                          │
│  ┌─────────────────┐                                            │
│  │ 1. 数据划分     │                                            │
│  │ • 训练集 70%    │                                            │
│  │ • 验证集 15%    │                                            │
│  │ • 测试集 15%    │  输出: X_train, X_val, X_test              │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 2. 超参数调优   │                                            │
│  │ • 网格搜索      │  ⚠️ 监控验证集: 若过拟合 → 增大正则化     │
│  │ • 5折交叉验证   │  输出: best_params                         │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 3. 模型训练     │                                            │
│  │ • 早停策略      │                                            │
│  │ • 特征重要性    │  输出: xgb_model, feature_importance       │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 4. SHAP分析     │                                            │
│  │ • TreeExplainer │                                            │
│  │ • 全局重要性    │  输出: shap_values, summary_plot           │
│  │ • 交互效应      │  输出: interaction_values                  │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  [输出: 特征重要性排序, SHAP依赖图, 交互效应矩阵]               │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## 四、问题四：新投票系统设计模型建立（创新方案）

### 4.1 NSGA-II多目标优化模型

#### 4.1.1 变量/特征定义

| 变量符号 | 变量名称 | 类型 | 字段含义 | 处理方式 | 分析意义 |
|---------|---------|------|---------|---------|---------|
| $\mathbf{w}$ | 权重向量 | 连续(决策) | 评委/粉丝权重 | 优化变量 | 系统参数 |
| $\theta$ | 淘汰阈值 | 连续(决策) | 危险区判定阈值 | 优化变量 | 系统参数 |
| $f_1$ | 公平性目标 | 连续(目标) | 技术与人气的平衡度 | 最大化 | 评价指标 |
| $f_2$ | 稳定性目标 | 连续(目标) | 淘汰结果的可预测性 | 最大化 | 评价指标 |
| $f_3$ | 娱乐性目标 | 连续(目标) | 赛事悬念与观赏性 | 最大化 | 评价指标 |

#### 4.1.2 假设条件

| 假设编号 | 假设内容 | 合理性说明 |
|---------|---------|-----------|
| **F1** | 历史数据可作为新系统模拟基础 | 选手特征与投票模式具有时间稳定性 |
| **F2** | 三个目标之间存在权衡关系 | 符合社会选择理论的阿罗不可能定理 |
| **F3** | 帕累托最优解集代表可行的系统设计空间 | 多目标优化的标准解释框架 |

#### 4.1.3 模型公式推导

**Step 1: 目标函数定义**

**公平性**（技术与人气的相关性）：
$$f_1(\mathbf{w}) = \text{Corr}\left( \text{Rank}^{\text{Judge}}, \text{Rank}^{\text{Final}}(\mathbf{w}) \right) \tag{19}$$

**稳定性**（淘汰结果的确定性）：
$$f_2(\mathbf{w}) = 1 - \frac{1}{W} \sum_{w=1}^W \text{Entropy}(P_{\text{elim}}^{(w)}) \tag{20}$$

**娱乐性**（赛事悬念）：
$$f_3(\mathbf{w}) = \frac{1}{W} \sum_{w=1}^W \mathbb{1}[\text{Upset}_w] \tag{21}$$

其中 $\text{Upset}_w$ 表示第w周是否出现"爆冷"（高排名选手被淘汰）。

**Step 2: NSGA-II算法**

```
初始化: 随机生成种群 P_0，规模N
For gen = 1 to G:
    1. 交叉变异生成子代 Q_gen
    2. 合并: R_gen = P_gen ∪ Q_gen
    3. 非支配排序: F_1, F_2, ...
    4. 拥挤度计算
    5. 选择: P_{gen+1} = 前N个个体
End
输出: 帕累托前沿 PF
```

**Step 3: 决策变量范围**

$$\mathbf{w} \in [0, 1]^2, \quad w_J + w_V = 1$$
$$\theta \in [0.1, 0.3]$$

#### 4.1.4 建模流程图

```
┌─────────────────────────────────────────────────────────────────┐
│                    NSGA-II多目标优化建模流程                     │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  [历史数据 + 问题一估算] ─────────────────────────────────────► │
│      │                                                          │
│      ▼                                                          │
│  ┌─────────────────┐                                            │
│  │ 1. 目标函数构建 │                                            │
│  │ • 公平性计算    │                                            │
│  │ • 稳定性计算    │                                            │
│  │ • 娱乐性计算    │  输出: objective_functions                 │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 2. NSGA-II配置  │                                            │
│  │ • 种群规模: 100 │                                            │
│  │ • 代数: 200     │                                            │
│  │ • 交叉率: 0.9   │  输出: nsga2_config                        │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 3. 进化迭代     │  ⚠️ 监控: 帕累托前沿收敛性                 │
│  │ • 非支配排序    │                                            │
│  │ • 拥挤度选择    │  输出: pareto_front                        │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 4. 决策分析     │                                            │
│  │ • 可视化PF      │  输出: pareto_plot                         │
│  │ • 推荐方案选择  │  输出: recommended_system                  │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  [输出: 帕累托前沿, 推荐系统参数, 目标权衡分析]                 │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## 五、符号统一说明

| 符号 | 含义 | 使用范围 |
|-----|------|---------|
| $i$ | 选手索引 | 全文 |
| $w$ | 周次索引 | 全文 |
| $s$ | 季数索引 | 全文 |
| $J_{i,w}$ | 评委总分 | 问题一、二、三 |
| $V_{i,w}$ | 粉丝投票比例 | 问题一、二 |
| $C_{i,w}$ | 综合得分 | 问题一、二 |
| $n_w$ | 第w周参赛人数 | 全文 |
| $\mathcal{E}_w$ | 第w周淘汰者集合 | 问题一、二 |
| $\beta$ | 固定效应系数 | 问题三 |
| $b$ | 随机效应 | 问题三 |
| $\phi$ | SHAP值 | 问题三 |
| $\mathbf{w}$ | 权重向量 | 问题四 |

---

## 附录：Python代码框架

```python
# ==========================================
# MCM 2026 Problem C - 模型建立代码框架
# 版本: v2.0
# ==========================================

import numpy as np
import pandas as pd
from scipy import stats
from scipy.optimize import minimize
import warnings

# ========== 问题一: 约束优化 + 先验正则化 ==========
def fan_vote_optimization(judge_scores, eliminations, rule_phase, lambda_entropy=0.1):
    """
    约束优化求解粉丝投票（方案一）
    
    Parameters:
    -----------
    judge_scores : array [n], 本周评委总分
    eliminations : list, 本周淘汰选手索引
    rule_phase : str, 'rank' 或 'percentage'
    lambda_entropy : float, 熵正则化系数
    
    Returns:
    --------
    V_optimal : array [n], 估算的粉丝投票比例
    """
    n = len(judge_scores)
    J_norm = judge_scores / np.sum(judge_scores)  # 归一化评委分
    
    # 目标函数: 最小化与先验的偏差 + 熵正则化
    def objective(V):
        # 先验: 粉丝倾向投高分选手
        prior_loss = np.sum((V - J_norm) ** 2)
        # 熵正则化: 鼓励多样性
        entropy = -np.sum(V * np.log(V + 1e-10))
        return prior_loss - lambda_entropy * entropy
    
    # 约束条件
    constraints = [
        {'type': 'eq', 'fun': lambda V: np.sum(V) - 1},  # 单纯形约束
    ]
    
    # 淘汰约束
    for elim_idx in eliminations:
        for k in range(n):
            if k != elim_idx:
                if rule_phase == 'percentage':
                    # 百分比制: J_norm[elim] + V[elim] < J_norm[k] + V[k]
                    constraints.append({
                        'type': 'ineq',
                        'fun': lambda V, e=elim_idx, k=k: (J_norm[k] + V[k]) - (J_norm[e] + V[e]) - 0.001
                    })
    
    # 边界约束
    bounds = [(0.01, 0.50) for _ in range(n)]
    
    # 求解
    result = minimize(
        objective,
        x0=np.ones(n) / n,
        method='SLSQP',
        constraints=constraints,
        bounds=bounds
    )
    
    return result.x if result.success else np.ones(n) / n

# ========== 问题一: 贝叶斯 + 狄利克雷 + 拒绝采样 ==========
def dirichlet_rejection_sampling(judge_scores, eliminations, rule_phase, 
                                  n_samples=5000, alpha_type='uniform'):
    """
    贝叶斯+狄利克雷+拒绝采样估算粉丝投票（方案二）
    
    Parameters:
    -----------
    judge_scores : array [n], 本周评委总分
    eliminations : list, 本周淘汰选手索引
    rule_phase : str, 'rank' 或 'percentage'
    n_samples : int, 目标样本数
    alpha_type : str, 'uniform' 或 'informative'
    
    Returns:
    --------
    samples : array [n_samples, n], 后验样本
    V_mean : array [n], 后验均值（点估计）
    V_ci : array [n, 2], 95% HPD区间
    acceptance_rate : float, 接受率
    """
    n = len(judge_scores)
    J_norm = judge_scores / np.sum(judge_scores)
    
    # 设置先验参数
    if alpha_type == 'uniform':
        alpha = np.ones(n)
    else:  # informative
        alpha = J_norm * n  # 信息性先验
    
    # 约束检验函数
    def satisfies_constraints(V):
        for elim_idx in eliminations:
            if rule_phase == 'percentage':
                elim_score = J_norm[elim_idx] + V[elim_idx]
                for k in range(n):
                    if k != elim_idx:
                        if elim_score >= J_norm[k] + V[k]:
                            return False
            else:  # rank
                J_ranks = stats.rankdata(-judge_scores)  # 降序排名
                V_ranks = stats.rankdata(-V)
                elim_total = J_ranks[elim_idx] + V_ranks[elim_idx]
                for k in range(n):
                    if k != elim_idx:
                        if elim_total <= J_ranks[k] + V_ranks[k]:
                            return False
        return True
    
    # 拒绝采样
    samples = []
    n_proposed = 0
    max_attempts = n_samples * 1000  # 防止无限循环
    
    while len(samples) < n_samples and n_proposed < max_attempts:
        V_proposal = np.random.dirichlet(alpha)
        n_proposed += 1
        
        if satisfies_constraints(V_proposal):
            samples.append(V_proposal)
    
    samples = np.array(samples)
    acceptance_rate = len(samples) / n_proposed
    
    if acceptance_rate < 0.01:
        warnings.warn(f"Low acceptance rate: {acceptance_rate:.4f}. Consider adaptive prior.")
    
    # 后验统计
    V_mean = np.mean(samples, axis=0)
    V_ci = np.percentile(samples, [2.5, 97.5], axis=0).T
    
    return samples, V_mean, V_ci, acceptance_rate

# ========== 问题二: Kendall τ + Bootstrap敏感性分析 ==========
def kendall_tau_bootstrap(V_samples, judge_scores, n_bootstrap=2000):
    """
    Kendall τ + Bootstrap敏感性分析（问题二）
    
    Parameters:
    -----------
    V_samples : array [B, n], 问题一后验样本
    judge_scores : array [n], 评委总分
    n_bootstrap : int, Bootstrap迭代次数
    
    Returns:
    --------
    tau_mean : float, τ系数点估计
    tau_ci : array [2], τ的95%置信区间
    diff_prob : float, 淘汰差异概率
    """
    J_norm = judge_scores / np.sum(judge_scores)
    n = len(judge_scores)
    
    tau_samples = []
    diff_samples = []
    
    for b in range(min(n_bootstrap, len(V_samples))):
        V = V_samples[b]
        
        # 排名制得分
        J_ranks = stats.rankdata(-judge_scores)
        V_ranks = stats.rankdata(-V)
        rank_score = J_ranks + V_ranks
        rank_final = stats.rankdata(rank_score)
        
        # 百分比制得分
        pct_score = J_norm + V
        pct_final = stats.rankdata(-pct_score)
        
        # Kendall τ
        tau, _ = stats.kendalltau(rank_final, pct_final)
        tau_samples.append(tau)
        
        # 淘汰差异（最低分者）
        rank_elim = np.argmax(rank_score)
        pct_elim = np.argmin(pct_score)
        diff_samples.append(1 if rank_elim != pct_elim else 0)
    
    tau_mean = np.mean(tau_samples)
    tau_ci = np.percentile(tau_samples, [2.5, 97.5])
    diff_prob = np.mean(diff_samples)
    
    return tau_mean, tau_ci, diff_prob

# ========== 问题三: 混合效应模型 (LMEM) ==========
def lmem_analysis(df):
    """
    线性混合效应模型（方案一）
    
    Parameters:
    -----------
    df : DataFrame, 包含 judge_score, age, industry, gender, pro_partner, season
    
    Returns:
    --------
    result : 模型拟合结果
    icc_pro : float, 舞伴ICC
    """
    import statsmodels.formula.api as smf
    
    model = smf.mixedlm(
        "judge_score ~ age + C(industry) + gender",
        df,
        groups=df["pro_partner"],
        re_formula="~1"
    )
    result = model.fit()
    
    # 计算ICC
    var_pro = result.cov_re.iloc[0, 0]  # 随机效应方差
    var_resid = result.scale  # 残差方差
    icc_pro = var_pro / (var_pro + var_resid)
    
    return result, icc_pro

# ========== 问题三: XGBoost + SHAP ==========
def xgboost_shap_analysis(X, y, feature_names=None):
    """
    XGBoost + SHAP可解释性分析（方案二）
    
    Parameters:
    -----------
    X : array [n_samples, n_features], 特征矩阵
    y : array [n_samples], 目标变量
    feature_names : list, 特征名称
    
    Returns:
    --------
    model : XGBoost模型
    shap_values : array, SHAP值
    feature_importance : DataFrame, 特征重要性排序
    """
    import xgboost as xgb
    import shap
    from sklearn.model_selection import train_test_split, GridSearchCV
    
    # 数据划分
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # 超参数调优
    param_grid = {
        'max_depth': [3, 5, 7],
        'n_estimators': [50, 100, 150],
        'learning_rate': [0.01, 0.1, 0.2],
        'reg_alpha': [0, 0.1, 1],
        'reg_lambda': [1, 2, 5]
    }
    
    model = xgb.XGBRegressor(random_state=42)
    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='r2', n_jobs=-1)
    grid_search.fit(X_train, y_train)
    
    best_model = grid_search.best_estimator_
    
    # SHAP分析
    explainer = shap.TreeExplainer(best_model)
    shap_values = explainer.shap_values(X_test)
    
    # 特征重要性
    importance = np.abs(shap_values).mean(axis=0)
    if feature_names is None:
        feature_names = [f'Feature_{i}' for i in range(X.shape[1])]
    
    feature_importance = pd.DataFrame({
        'Feature': feature_names,
        'Importance': importance
    }).sort_values('Importance', ascending=False)
    
    return best_model, shap_values, feature_importance

# ========== 问题四: NSGA-II + 帕累托前沿 ==========
def nsga2_voting_system(historical_data, V_estimates, n_generations=200, pop_size=100):
    """
    NSGA-II多目标优化设计新投票系统（问题四）
    
    Parameters:
    -----------
    historical_data : DataFrame, 历史数据
    V_estimates : dict, 各周投票估算
    n_generations : int, 进化代数
    pop_size : int, 种群规模
    
    Returns:
    --------
    pareto_front : array [n_solutions, 3], 帕累托前沿目标值
    pareto_solutions : array [n_solutions, 2], 对应的决策变量
    recommended : dict, 推荐方案
    """
    from pymoo.algorithms.moo.nsga2 import NSGA2
    from pymoo.core.problem import Problem
    from pymoo.optimize import minimize as pymoo_minimize
    from pymoo.termination import get_termination
    
    class VotingSystemProblem(Problem):
        def __init__(self, data, V_est):
            super().__init__(
                n_var=2,  # [judge_weight, danger_threshold]
                n_obj=3,  # [fairness, stability, entertainment]
                n_constr=0,
                xl=np.array([0.3, 0.1]),  # 下界
                xu=np.array([0.7, 0.3])   # 上界
            )
            self.data = data
            self.V_est = V_est
        
        def _evaluate(self, X, out, *args, **kwargs):
            F = np.zeros((X.shape[0], 3))
            
            for i, x in enumerate(X):
                w_judge = x[0]
                threshold = x[1]
                
                # 目标1: 公平性（技术与最终排名相关性）
                fairness = self._compute_fairness(w_judge)
                
                # 目标2: 稳定性（淘汰确定性）
                stability = self._compute_stability(w_judge, threshold)
                
                # 目标3: 娱乐性（爆冷率）
                entertainment = self._compute_entertainment(w_judge)
                
                # 取负（pymoo默认最小化）
                F[i] = [-fairness, -stability, -entertainment]
            
            out["F"] = F
        
        def _compute_fairness(self, w_judge):
            # 简化: 评委权重越高，公平性越高
            return w_judge * 0.8 + 0.2
        
        def _compute_stability(self, w_judge, threshold):
            # 简化: 阈值越低，稳定性越高
            return 1 - threshold
        
        def _compute_entertainment(self, w_judge):
            # 简化: 粉丝权重越高，娱乐性越高
            return 1 - w_judge
    
    problem = VotingSystemProblem(historical_data, V_estimates)
    algorithm = NSGA2(pop_size=pop_size)
    termination = get_termination("n_gen", n_generations)
    
    res = pymoo_minimize(problem, algorithm, termination, seed=42, verbose=False)
    
    # 帕累托前沿（转为最大化）
    pareto_front = -res.F
    pareto_solutions = res.X
    
    # 推荐方案: 选择平衡点（距离理想点最近）
    ideal = np.max(pareto_front, axis=0)
    distances = np.linalg.norm(pareto_front - ideal, axis=1)
    best_idx = np.argmin(distances)
    
    recommended = {
        'judge_weight': pareto_solutions[best_idx, 0],
        'fan_weight': 1 - pareto_solutions[best_idx, 0],
        'danger_threshold': pareto_solutions[best_idx, 1],
        'fairness': pareto_front[best_idx, 0],
        'stability': pareto_front[best_idx, 1],
        'entertainment': pareto_front[best_idx, 2]
    }
    
    return pareto_front, pareto_solutions, recommended


# ========== 主程序示例 ==========
if __name__ == "__main__":
    print("=" * 60)
    print("MCM 2026 Problem C - 模型建立代码框架")
    print("=" * 60)
    
    # 示例: 问题一约束优化
    print("\n[问题一] 约束优化测试:")
    J = np.array([28, 25, 22, 20, 18])  # 5位选手评委分
    elim = [4]  # 第5位被淘汰
    V_opt = fan_vote_optimization(J, elim, 'percentage')
    print(f"  估算投票比例: {V_opt}")
    
    # 示例: 问题一拒绝采样
    print("\n[问题一] 拒绝采样测试:")
    samples, V_mean, V_ci, acc_rate = dirichlet_rejection_sampling(
        J, elim, 'percentage', n_samples=1000
    )
    print(f"  后验均值: {V_mean}")
    print(f"  接受率: {acc_rate:.2%}")
    
    # 示例: 问题二Kendall τ
    print("\n[问题二] Kendall τ测试:")
    tau, tau_ci, diff_prob = kendall_tau_bootstrap(samples, J, n_bootstrap=500)
    print(f"  τ系数: {tau:.3f} (95% CI: [{tau_ci[0]:.3f}, {tau_ci[1]:.3f}])")
    print(f"  淘汰差异概率: {diff_prob:.2%}")
    
    print("\n" + "=" * 60)
    print("代码框架测试完成!")
```

---

**文档结束**

> 本文档为MCM 2026 Problem C的模型建立模块v2.0，涵盖：
> - 问题一双方案：约束优化+先验正则化、贝叶斯+狄利克雷+拒绝采样
> - 问题二创新方案：Kendall τ + Bootstrap敏感性分析
> - 问题三双方案：混合效应模型(LMEM)、XGBoost+SHAP
> - 问题四创新方案：NSGA-II + 帕累托前沿