# 模型建立模块

> **版本**: v1.0  
> **适用题目**: MCM 2026 Problem C - Dancing with the Stars  
> **先导要求**: 问题一双方案、问题二创新、问题三双方案、问题四创新

---

## 目录

1. [问题一：粉丝投票估算模型建立](#一问题一粉丝投票估算模型建立)
2. [问题二：投票方法比较模型建立](#二问题二投票方法比较模型建立)
3. [问题三：影响因素分析模型建立](#三问题三影响因素分析模型建立)
4. [问题四：新投票系统设计模型建立](#四问题四新投票系统设计模型建立)
5. [符号统一说明](#五符号统一说明)

---

## 一、问题一：粉丝投票估算模型建立

### 1.1 方案一：约束优化模型

#### 1.1.1 变量/特征定义

| 变量符号 | 变量名称 | 类型 | 字段含义 | 处理方式 | 分析意义 |
|---------|---------|------|---------|---------|---------|
| $J_{i,w}$ | 评委总分 | 连续(原始) | 选手i在第w周的评委总分 | 直接使用/归一化 | 反映舞蹈技术水平 |
| $V_{i,w}$ | 粉丝投票比例 | 连续(目标) | 选手i在第w周的粉丝投票占比 | **待估算** | 逆向推断目标变量 |
| $E_{i,w}$ | 淘汰标记 | 离散(原始) | 选手i在第w周是否被淘汰 | 0/1编码 | 约束条件验证 |
| $n_w$ | 参赛人数 | 离散(衍生) | 第w周参赛选手数量 | 统计计算 | 动态约束边界 |
| $R^J_{i,w}$ | 评委排名 | 离散(衍生) | 基于评委分的周内排名 | 降序排序 | 排名制合并依据 |
| $R^V_{i,w}$ | 粉丝排名 | 离散(目标) | 基于粉丝投票的周内排名 | **待推断** | 排名制合并依据 |

#### 1.1.2 假设条件

| 假设编号 | 假设内容 | 合理性说明 |
|---------|---------|-----------|
| **A1** | 粉丝投票比例服从单纯形约束：$\sum_{i=1}^{n_w} V_{i,w} = 1$，$V_{i,w} \geq 0$ | 投票为零和博弈，总票数固定，符合比例分配逻辑 |
| **A2** | 淘汰者为综合得分最低者（无平局） | 题目规则明确，数据中未出现平局淘汰记录 |
| **A3** | 评委评分与粉丝投票相互独立 | 评委打分在投票前公布，但投票已开始，假设独立可简化模型 |
| **A4** | 同一季内粉丝投票分布相对稳定 | 粉丝基础短期内不会剧烈变化，允许跨周信息借鉴 |

#### 1.1.3 模型公式推导

**Step 1: 定义综合得分函数**

根据投票规则阶段，定义综合得分：

- **排名制（S1-2, S28-34）**:
$$C_{i,w} = R^J_{i,w} + R^V_{i,w} \tag{1}$$

- **百分比制（S3-27）**:
$$C_{i,w} = \frac{J_{i,w}}{\sum_{j=1}^{n_w} J_{j,w}} + V_{i,w} \tag{2}$$

**Step 2: 淘汰约束条件**

设第w周被淘汰选手集合为 $\mathcal{E}_w$，则：
$$\forall e \in \mathcal{E}_w, \forall i \notin \mathcal{E}_w: C_{e,w} < C_{i,w} \tag{3}$$

即淘汰者的综合得分严格低于所有存活者。

**Step 3: 约束优化目标函数**

引入正则化项，构建优化问题：

$$\min_{\{V_{i,w}\}} \sum_{w=1}^{W} \sum_{i=1}^{n_w} \left( V_{i,w} - \bar{V}_i \right)^2 + \lambda \cdot \text{Entropy}(V_w) \tag{4}$$

**约束条件**:
- 单纯形约束: $\sum_{i=1}^{n_w} V_{i,w} = 1$, $V_{i,w} \geq 0$
- 淘汰约束: 式(3)对所有周成立
- 边界约束: $V_{i,w} \in [0.01, 0.50]$（经验边界）

**Step 4: 求解方法**

采用序列二次规划(SQP)或内点法求解：

```
初始化: V⁰ ~ Uniform(1/n)
迭代:
  计算梯度: ∇L = 2(V - V̄) - λ∇H(V)
  更新: V^(k+1) = V^k - α·∇L
  投影到可行域: V = Project(V, Constraints)
终止: ||V^(k+1) - V^k|| < ε
```

#### 1.1.4 建模流程图

```
┌─────────────────────────────────────────────────────────────────┐
│                      约束优化模型建模流程                        │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  [数据输入] ─────────────────────────────────────────────────►  │
│      │                                                          │
│      ▼                                                          │
│  ┌─────────────────┐                                            │
│  │ 1. 数据预处理   │                                            │
│  │ • 识别规则阶段  │  输出: rule_phase ∈ {1,2,3}               │
│  │ • 提取淘汰信息  │  输出: elimination_dict                    │
│  │ • 计算评委排名  │  输出: judge_ranks                         │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 2. 约束构建     │  ⚠️ 关键节点：验证约束可行性               │
│  │ • 单纯形约束    │     若无可行解 → 放松边界约束              │
│  │ • 淘汰约束      │                                            │
│  │ • 边界约束      │  输出: constraint_matrix A, b              │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 3. 优化求解     │                                            │
│  │ • 初始化V⁰     │                                            │
│  │ • SQP迭代      │  ⚠️ 监控收敛性：若不收敛 → 调整λ           │
│  │ • 投影到可行域  │  输出: V_optimal, convergence_curve        │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 4. 结果验证     │                                            │
│  │ • 约束满足检查  │  输出: constraint_satisfaction_rate        │
│  │ • 淘汰一致性    │  输出: elimination_accuracy                │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  [输出: 粉丝投票估算值 V̂_{i,w}]                                 │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

### 1.2 方案二：贝叶斯MCMC模型

#### 1.2.1 变量/特征定义

| 变量符号 | 变量名称 | 类型 | 字段含义 | 处理方式 | 分析意义 |
|---------|---------|------|---------|---------|---------|
| $\boldsymbol{V}_w$ | 投票向量 | 连续(目标) | 第w周所有选手投票比例 | 狄利克雷采样 | 联合估算对象 |
| $\boldsymbol{\alpha}_w$ | 狄利克雷参数 | 连续(隐变量) | 投票分布的集中度参数 | MCMC推断 | 控制不确定性 |
| $\mathcal{D}$ | 观测数据 | - | 评委分+淘汰结果 | 似然计算 | 后验更新依据 |

#### 1.2.2 假设条件

| 假设编号 | 假设内容 | 合理性说明 |
|---------|---------|-----------|
| **B1** | 粉丝投票服从狄利克雷分布：$\boldsymbol{V}_w \sim \text{Dir}(\boldsymbol{\alpha}_w)$ | 狄利克雷是单纯形上的共轭先验，数学形式自然匹配投票比例 |
| **B2** | 先验参数 $\alpha_i = 1$（均匀先验） | 无强先验信息时的最大熵选择 |
| **B3** | 淘汰事件为似然函数的硬约束 | 观测到的淘汰结果提供强信息 |

#### 1.2.3 模型公式推导

**Step 1: 定义先验分布**

$$\boldsymbol{V}_w \sim \text{Dirichlet}(\alpha_1, \alpha_2, ..., \alpha_{n_w}) \tag{5}$$

其中 $\alpha_i = 1$ 对应均匀先验。

**Step 2: 定义似然函数**

基于淘汰约束，定义似然：
$$P(\mathcal{D}_w | \boldsymbol{V}_w) = \begin{cases} 1 & \text{if } \boldsymbol{V}_w \text{ 满足淘汰约束} \\ 0 & \text{otherwise} \end{cases} \tag{6}$$

这是一个截断似然（truncated likelihood）。

**Step 3: 后验分布**

由贝叶斯定理：
$$P(\boldsymbol{V}_w | \mathcal{D}_w) \propto P(\mathcal{D}_w | \boldsymbol{V}_w) \cdot P(\boldsymbol{V}_w) \tag{7}$$

后验为约束域上的狄利克雷分布。

**Step 4: MCMC采样算法**

采用Metropolis-Hastings算法：

```python
# MCMC采样伪代码
def mcmc_sampling(n_samples, n_burnin):
    V_current = sample_dirichlet(alpha)  # 初始化
    samples = []
    
    for t in range(n_samples + n_burnin):
        # 提议新样本
        V_proposal = sample_dirichlet(V_current * concentration)
        
        # 计算接受概率
        if satisfies_constraints(V_proposal):
            alpha_ratio = acceptance_ratio(V_current, V_proposal)
            if random() < alpha_ratio:
                V_current = V_proposal
        
        if t >= n_burnin:
            samples.append(V_current)
    
    return samples
```

**Step 5: 点估计与置信区间**

- 点估计：后验均值 $\hat{V}_{i,w} = \mathbb{E}[V_{i,w} | \mathcal{D}]$
- 置信区间：95% HPD区间

#### 1.2.4 建模流程图

```
┌─────────────────────────────────────────────────────────────────┐
│                    贝叶斯MCMC模型建模流程                        │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  [先验设置] ──────────────────────────────────────────────────► │
│      │         α = (1,1,...,1)                                  │
│      ▼                                                          │
│  ┌─────────────────┐                                            │
│  │ 1. 约束域定义   │                                            │
│  │ • 单纯形约束    │                                            │
│  │ • 淘汰约束转化  │  输出: feasible_region                     │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 2. MCMC初始化   │                                            │
│  │ • 从先验采样    │                                            │
│  │ • 拒绝不满足约束│  ⚠️ 若拒绝率>95% → 使用切片采样           │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 3. MCMC迭代     │                                            │
│  │ • Burn-in: 1000 │                                            │
│  │ • Samples: 5000 │  ⚠️ 监控: Gelman-Rubin R̂ < 1.1            │
│  │ • Thinning: 10  │  输出: posterior_samples                   │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 4. 后验分析     │                                            │
│  │ • 计算后验均值  │  输出: V̂ (点估计)                          │
│  │ • 计算HPD区间   │  输出: CI_95 (置信区间)                    │
│  │ • 有效样本量    │  输出: ESS (诊断指标)                      │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  [输出: 后验分布 P(V|D), 点估计, 置信区间]                      │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## 二、问题二：投票方法比较模型建立（创新方案）

### 2.1 Bootstrap反事实推演模型

#### 2.1.1 变量/特征定义

| 变量符号 | 变量名称 | 类型 | 字段含义 | 处理方式 | 分析意义 |
|---------|---------|------|---------|---------|---------|
| $\hat{V}_{i,w}$ | 估算投票比例 | 连续(输入) | 问题一估算结果 | 直接使用 | 反事实模拟输入 |
| $O^{obs}_w$ | 实际淘汰结果 | 离散(原始) | 历史真实淘汰记录 | 编码为选手ID | 对照基准 |
| $O^{cf}_w$ | 反事实淘汰结果 | 离散(衍生) | 假设另一规则的淘汰 | 模拟计算 | 规则差异量化 |
| $\Delta_w$ | 结果差异指标 | 离散(衍生) | $\mathbb{1}[O^{obs}_w \neq O^{cf}_w]$ | 0/1编码 | 规则影响度 |

#### 2.1.2 假设条件

| 假设编号 | 假设内容 | 合理性说明 |
|---------|---------|-----------|
| **C1** | 粉丝投票不因规则变化而改变 | 投票行为主要由粉丝偏好驱动，短期内规则感知有限 |
| **C2** | 估算的投票比例具有足够精度 | 问题一模型验证通过后，可作为反事实输入 |
| **C3** | 规则变化仅影响合并方式，不影响评委打分 | 评委独立评分，不受合并规则影响 |

#### 2.1.3 模型公式推导

**Step 1: 反事实得分计算**

对于百分比制季（S3-27），模拟排名制：
$$C^{cf}_{i,w} = \text{Rank}(J_{i,w}) + \text{Rank}(\hat{V}_{i,w}) \tag{8}$$

对于排名制季（S1-2, S28-34），模拟百分比制：
$$C^{cf}_{i,w} = \frac{J_{i,w}}{\sum_j J_{j,w}} + \hat{V}_{i,w} \tag{9}$$

**Step 2: Bootstrap不确定性传播**

由于 $\hat{V}$ 存在估算误差，采用Bootstrap量化：

```
For b = 1 to B (B=1000):
    V^{(b)} ~ P(V|D)  # 从问题一后验采样
    计算 O^{cf,(b)}_w  # 反事实淘汰
    计算 Δ^{(b)}_w    # 差异指标
End

统计: P(规则差异) = mean(Δ^{(b)})
置信区间: [Δ_{2.5%}, Δ_{97.5%}]
```

**Step 3: 争议案例深度分析**

对于Jerry Rice、Bristol Palin等争议案例：
$$\text{Controversy Score} = P(O^{obs} \neq O^{cf}) \cdot |\text{Rank}^{obs} - \text{Rank}^{cf}| \tag{10}$$

#### 2.1.4 建模流程图

```
┌─────────────────────────────────────────────────────────────────┐
│                  Bootstrap反事实推演建模流程                     │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  [问题一输出: P(V|D)] ────────────────────────────────────────► │
│      │                                                          │
│      ▼                                                          │
│  ┌─────────────────┐                                            │
│  │ 1. 后验采样     │                                            │
│  │ • 采样B=1000次  │  输出: V_samples[B, n, W]                  │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 2. 反事实模拟   │                                            │
│  │ • 计算替代规则分│                                            │
│  │ • 确定反事实淘汰│  输出: O_cf_samples[B, W]                  │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 3. 差异统计     │                                            │
│  │ • 计算Δ分布     │  输出: delta_distribution                  │
│  │ • McNemar检验   │  输出: p_value, chi2_stat                  │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 4. 争议案例分析 │  ⚠️ 重点关注: Bristol Palin, Bobby Bones  │
│  │ • 识别高争议周  │                                            │
│  │ • 计算争议得分  │  输出: controversy_report                  │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  [输出: 规则差异概率, 置信区间, 争议案例报告]                   │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## 三、问题三：影响因素分析模型建立

### 3.1 方案一：线性混合效应模型(LMEM)

#### 3.1.1 变量/特征定义

| 变量符号 | 变量名称 | 类型 | 字段含义 | 处理方式 | 分析意义 |
|---------|---------|------|---------|---------|---------|
| $Y_{i,w}$ | 响应变量 | 连续(目标) | 评委总分或存活周数 | 直接使用 | 表现度量 |
| $\text{Age}_i$ | 年龄 | 连续(原始) | 参赛时年龄 | 标准化 | 体能/经验代理 |
| $\text{Industry}_i$ | 行业 | 离散(原始) | 名人职业类别 | One-Hot编码 | 粉丝基础代理 |
| $\text{Gender}_i$ | 性别 | 离散(原始) | 男/女 | 0/1编码 | 控制变量 |
| $\text{Pro}_i$ | 专业舞伴 | 离散(原始) | 配对舞伴ID | **随机效应** | 舞伴影响量化 |
| $\text{Season}_i$ | 季数 | 离散(原始) | 参赛季编号 | **随机效应** | 时间趋势控制 |

#### 3.1.2 假设条件

| 假设编号 | 假设内容 | 合理性说明 |
|---------|---------|-----------|
| **D1** | 随机效应服从正态分布：$b_{\text{Pro}} \sim N(0, \sigma^2_{\text{Pro}})$ | 标准混合效应模型假设，便于参数估计 |
| **D2** | 残差独立同分布：$\epsilon \sim N(0, \sigma^2)$ | 同一选手跨周数据通过随机效应建模关联 |
| **D3** | 固定效应与随机效应正交 | 设计矩阵构建时验证 |

#### 3.1.3 模型公式推导

**Step 1: 混合效应模型公式**

$$Y_{i,w} = \underbrace{\beta_0 + \beta_1 \cdot \text{Age}_i + \sum_k \beta_k \cdot \text{Industry}_{ik}}_{\text{固定效应}} + \underbrace{b_{\text{Pro}(i)} + b_{\text{Season}(i)}}_{\text{随机效应}} + \epsilon_{i,w} \tag{11}$$

**Step 2: 方差分量估计**

总方差分解：
$$\text{Var}(Y) = \sigma^2_{\text{Pro}} + \sigma^2_{\text{Season}} + \sigma^2_\epsilon \tag{12}$$

舞伴解释方差比（ICC）：
$$\text{ICC}_{\text{Pro}} = \frac{\sigma^2_{\text{Pro}}}{\sigma^2_{\text{Pro}} + \sigma^2_{\text{Season}} + \sigma^2_\epsilon} \tag{13}$$

**Step 3: 参数估计（REML）**

采用限制最大似然估计：
$$\ell_{\text{REML}}(\theta) = -\frac{1}{2} \left[ \log|V| + \log|X'V^{-1}X| + (Y-X\hat{\beta})'V^{-1}(Y-X\hat{\beta}) \right] \tag{14}$$

#### 3.1.4 建模流程图

```
┌─────────────────────────────────────────────────────────────────┐
│                    LMEM混合效应模型建模流程                      │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  [预处理数据] ────────────────────────────────────────────────► │
│      │                                                          │
│      ▼                                                          │
│  ┌─────────────────┐                                            │
│  │ 1. 特征工程     │                                            │
│  │ • 年龄标准化    │                                            │
│  │ • 行业One-Hot   │  ⚠️ 检查多重共线性: VIF < 5               │
│  │ • 舞伴编码      │  输出: design_matrix X, Z                  │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 2. 模型拟合     │                                            │
│  │ • REML估计      │                                            │
│  │ • 方差分量计算  │  输出: beta_hat, sigma_estimates           │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 3. 显著性检验   │                                            │
│  │ • 固定效应t检验 │  输出: p_values_fixed                      │
│  │ • 随机效应LRT   │  输出: p_values_random                     │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 4. ICC计算      │                                            │
│  │ • 舞伴ICC       │  输出: ICC_pro (舞伴解释比例)              │
│  │ • 季节ICC       │  输出: ICC_season                          │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  [输出: 效应系数, 显著性, 方差分解]                             │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

### 3.2 方案二：XGBoost + SHAP可解释性模型

#### 3.2.1 变量/特征定义

| 变量符号 | 变量名称 | 类型 | 字段含义 | 处理方式 | 分析意义 |
|---------|---------|------|---------|---------|---------|
| $\mathbf{X}_i$ | 特征向量 | 混合(输入) | 所有候选特征 | 编码+标准化 | 模型输入 |
| $Y_i$ | 存活周数 | 连续(目标) | 参赛持续周数 | 直接使用 | 预测目标 |
| $\phi_j$ | SHAP值 | 连续(衍生) | 特征j的边际贡献 | SHAP计算 | 特征重要性 |

#### 3.2.2 假设条件

| 假设编号 | 假设内容 | 合理性说明 |
|---------|---------|-----------|
| **E1** | 特征与目标存在非线性关系 | 树模型自动捕捉，无需预设函数形式 |
| **E2** | SHAP值具有加性分解性质 | Shapley值的数学性质保证 |
| **E3** | 训练数据代表总体分布 | 34季数据覆盖足够时间跨度 |

#### 3.2.3 模型公式推导

**Step 1: XGBoost目标函数**

$$\mathcal{L}(\theta) = \sum_{i=1}^n L(y_i, \hat{y}_i) + \sum_{k=1}^K \Omega(f_k) \tag{15}$$

其中正则化项：
$$\Omega(f) = \gamma T + \frac{1}{2}\lambda \sum_{j=1}^T w_j^2 \tag{16}$$

**Step 2: SHAP值计算**

基于Shapley值的特征贡献：
$$\phi_j = \sum_{S \subseteq N \setminus \{j\}} \frac{|S|!(|N|-|S|-1)!}{|N|!} [f(S \cup \{j\}) - f(S)] \tag{17}$$

**Step 3: 特征重要性排序**

全局重要性：
$$\text{Importance}_j = \frac{1}{n} \sum_{i=1}^n |\phi_j^{(i)}| \tag{18}$$

#### 3.2.4 建模流程图

```
┌─────────────────────────────────────────────────────────────────┐
│                  XGBoost + SHAP建模流程                          │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  [特征矩阵] ──────────────────────────────────────────────────► │
│      │                                                          │
│      ▼                                                          │
│  ┌─────────────────┐                                            │
│  │ 1. 数据划分     │                                            │
│  │ • 训练集 70%    │                                            │
│  │ • 验证集 15%    │                                            │
│  │ • 测试集 15%    │  输出: X_train, X_val, X_test              │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 2. 超参数调优   │                                            │
│  │ • 网格搜索      │  ⚠️ 监控验证集: 若过拟合 → 增大正则化     │
│  │ • 5折交叉验证   │  输出: best_params                         │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 3. 模型训练     │                                            │
│  │ • 早停策略      │                                            │
│  │ • 特征重要性    │  输出: xgb_model, feature_importance       │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 4. SHAP分析     │                                            │
│  │ • TreeExplainer │                                            │
│  │ • 全局重要性    │  输出: shap_values, summary_plot           │
│  │ • 交互效应      │  输出: interaction_values                  │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  [输出: 特征重要性排序, SHAP依赖图, 交互效应矩阵]               │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## 四、问题四：新投票系统设计模型建立（创新方案）

### 4.1 NSGA-II多目标优化模型

#### 4.1.1 变量/特征定义

| 变量符号 | 变量名称 | 类型 | 字段含义 | 处理方式 | 分析意义 |
|---------|---------|------|---------|---------|---------|
| $\mathbf{w}$ | 权重向量 | 连续(决策) | 评委/粉丝权重 | 优化变量 | 系统参数 |
| $\theta$ | 淘汰阈值 | 连续(决策) | 危险区判定阈值 | 优化变量 | 系统参数 |
| $f_1$ | 公平性目标 | 连续(目标) | 技术与人气的平衡度 | 最大化 | 评价指标 |
| $f_2$ | 稳定性目标 | 连续(目标) | 淘汰结果的可预测性 | 最大化 | 评价指标 |
| $f_3$ | 娱乐性目标 | 连续(目标) | 赛事悬念与观赏性 | 最大化 | 评价指标 |

#### 4.1.2 假设条件

| 假设编号 | 假设内容 | 合理性说明 |
|---------|---------|-----------|
| **F1** | 历史数据可作为新系统模拟基础 | 选手特征与投票模式具有时间稳定性 |
| **F2** | 三个目标之间存在权衡关系 | 符合社会选择理论的阿罗不可能定理 |
| **F3** | 帕累托最优解集代表可行的系统设计空间 | 多目标优化的标准解释框架 |

#### 4.1.3 模型公式推导

**Step 1: 目标函数定义**

**公平性**（技术与人气的相关性）：
$$f_1(\mathbf{w}) = \text{Corr}\left( \text{Rank}^{\text{Judge}}, \text{Rank}^{\text{Final}}(\mathbf{w}) \right) \tag{19}$$

**稳定性**（淘汰结果的确定性）：
$$f_2(\mathbf{w}) = 1 - \frac{1}{W} \sum_{w=1}^W \text{Entropy}(P_{\text{elim}}^{(w)}) \tag{20}$$

**娱乐性**（赛事悬念）：
$$f_3(\mathbf{w}) = \frac{1}{W} \sum_{w=1}^W \mathbb{1}[\text{Upset}_w] \tag{21}$$

其中 $\text{Upset}_w$ 表示第w周是否出现"爆冷"（高排名选手被淘汰）。

**Step 2: NSGA-II算法**

```
初始化: 随机生成种群 P_0，规模N
For gen = 1 to G:
    1. 交叉变异生成子代 Q_gen
    2. 合并: R_gen = P_gen ∪ Q_gen
    3. 非支配排序: F_1, F_2, ...
    4. 拥挤度计算
    5. 选择: P_{gen+1} = 前N个个体
End
输出: 帕累托前沿 PF
```

**Step 3: 决策变量范围**

$$\mathbf{w} \in [0, 1]^2, \quad w_J + w_V = 1$$
$$\theta \in [0.1, 0.3]$$

#### 4.1.4 建模流程图

```
┌─────────────────────────────────────────────────────────────────┐
│                    NSGA-II多目标优化建模流程                     │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  [历史数据 + 问题一估算] ─────────────────────────────────────► │
│      │                                                          │
│      ▼                                                          │
│  ┌─────────────────┐                                            │
│  │ 1. 目标函数构建 │                                            │
│  │ • 公平性计算    │                                            │
│  │ • 稳定性计算    │                                            │
│  │ • 娱乐性计算    │  输出: objective_functions                 │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 2. NSGA-II配置  │                                            │
│  │ • 种群规模: 100 │                                            │
│  │ • 代数: 200     │                                            │
│  │ • 交叉率: 0.9   │  输出: nsga2_config                        │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 3. 进化迭代     │  ⚠️ 监控: 帕累托前沿收敛性                 │
│  │ • 非支配排序    │                                            │
│  │ • 拥挤度选择    │  输出: pareto_front                        │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  ┌─────────────────┐                                            │
│  │ 4. 决策分析     │                                            │
│  │ • 可视化PF      │  输出: pareto_plot                         │
│  │ • 推荐方案选择  │  输出: recommended_system                  │
│  └────────┬────────┘                                            │
│           │                                                     │
│           ▼                                                     │
│  [输出: 帕累托前沿, 推荐系统参数, 目标权衡分析]                 │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## 五、符号统一说明

| 符号 | 含义 | 使用范围 |
|-----|------|---------|
| $i$ | 选手索引 | 全文 |
| $w$ | 周次索引 | 全文 |
| $s$ | 季数索引 | 全文 |
| $J_{i,w}$ | 评委总分 | 问题一、二、三 |
| $V_{i,w}$ | 粉丝投票比例 | 问题一、二 |
| $C_{i,w}$ | 综合得分 | 问题一、二 |
| $n_w$ | 第w周参赛人数 | 全文 |
| $\mathcal{E}_w$ | 第w周淘汰者集合 | 问题一、二 |
| $\beta$ | 固定效应系数 | 问题三 |
| $b$ | 随机效应 | 问题三 |
| $\phi$ | SHAP值 | 问题三 |
| $\mathbf{w}$ | 权重向量 | 问题四 |

---

## 附录：Python代码框架

```python
# ==========================================
# MCM 2026 Problem C - 模型建立代码框架
# ==========================================

# ========== 问题一: 约束优化 ==========
from scipy.optimize import minimize

def fan_vote_optimization(judge_scores, eliminations, rule_phase):
    """
    约束优化求解粉丝投票
    """
    n = len(judge_scores)
    
    # 目标函数: 最小化方差 + 熵正则化
    def objective(V):
        variance = np.var(V)
        entropy = -np.sum(V * np.log(V + 1e-10))
        return variance - 0.1 * entropy
    
    # 约束条件
    constraints = [
        {'type': 'eq', 'fun': lambda V: np.sum(V) - 1},  # 单纯形
        {'type': 'ineq', 'fun': lambda V: V - 0.01},     # 下界
    ]
    
    # 求解
    result = minimize(objective, x0=np.ones(n)/n, constraints=constraints)
    return result.x

# ========== 问题一: 贝叶斯MCMC ==========
import pymc3 as pm

def bayesian_mcmc_estimation(judge_scores, eliminations):
    """
    贝叶斯MCMC估算粉丝投票
    """
    n = len(judge_scores)
    
    with pm.Model() as model:
        # 狄利克雷先验
        V = pm.Dirichlet('V', a=np.ones(n))
        
        # 似然（通过势函数实现约束）
        # ... 约束实现
        
        # MCMC采样
        trace = pm.sample(5000, tune=1000, cores=2)
    
    return trace

# ========== 问题三: LMEM ==========
import statsmodels.formula.api as smf

def lmem_analysis(df):
    """
    线性混合效应模型
    """
    model = smf.mixedlm(
        "judge_score ~ age + C(industry) + gender",
        df,
        groups=df["pro_partner"],
        re_formula="~1"
    )
    result = model.fit()
    return result

# ========== 问题三: XGBoost + SHAP ==========
import xgboost as xgb
import shap

def xgboost_shap_analysis(X, y):
    """
    XGBoost + SHAP可解释性分析
    """
    # 训练模型
    model = xgb.XGBRegressor(n_estimators=100, max_depth=5)
    model.fit(X, y)
    
    # SHAP分析
    explainer = shap.TreeExplainer(model)
    shap_values = explainer.shap_values(X)
    
    return model, shap_values

# ========== 问题四: NSGA-II ==========
from pymoo.algorithms.moo.nsga2 import NSGA2
from pymoo.optimize import minimize as pymoo_minimize

def nsga2_optimization():
    """
    NSGA-II多目标优化
    """
    from pymoo.core.problem import Problem
    
    class VotingSystemProblem(Problem):
        def __init__(self):
            super().__init__(n_var=2, n_obj=3, n_constr=0,
                           xl=np.array([0, 0.1]),
                           xu=np.array([1, 0.3]))
        
        def _evaluate(self, x, out, *args, **kwargs):
            # 计算三个目标
            f1 = compute_fairness(x)
            f2 = compute_stability(x)
            f3 = compute_entertainment(x)
            out["F"] = np.column_stack([f1, f2, f3])
    
    problem = VotingSystemProblem()
    algorithm = NSGA2(pop_size=100)
    res = pymoo_minimize(problem, algorithm, ('n_gen', 200))
    
    return res.F, res.X  # 帕累托前沿, 对应解
```

---

**文档结束**

> 本文档为MCM 2026 Problem C的模型建立模块，涵盖问题一双方案、问题二创新方案、问题三双方案、问题四创新方案的完整建模过程。