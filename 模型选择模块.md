# 模型选择模块（优化版 v2.0）
## MCM 2026 Problem C: Data With The Stars

> **设计原则**：基于问题数学本质和数据特征进行原理分析，提供「基础保分方案」+「创新冲奖方案」双轨策略。模型选择必须有充分的数学/统计学依据，禁止盲目套用热门模型。

---

## 参考资料模型统计与批判性分析

### 模型出现频次统计（仅供参考，不作为选择依据）

| 模型 | 出现次数 | 主要应用问题 |
|------|----------|--------------|
| XGBoost | 32 | 问题三（影响因素） |
| 约束优化 | 31 | 问题一（投票估算） |
| 回归分析 | 27 | 问题三（影响因素） |
| SHAP | 27 | 问题三（可解释性） |
| NSGA多目标优化 | 22 | 问题四（新系统设计） |
| 随机森林 | 16 | 问题三（影响因素） |
| 贝叶斯MCMC | 14 | 问题一（不确定性量化） |
| 蒙特卡洛 | 9 | 问题一（采样验证） |
| 香农熵 | 9 | 问题一（确定性度量） |
| 动态权重 | 8 | 问题四（新系统设计） |
| 狄利克雷分布 | 6 | 问题一（先验设计） |
| Kendall系数 | 5 | 问题二（排名相关性） |
| 反事实推演 | 5 | 问题二（方法比较） |
| 混合效应模型 | 4 | 问题三（舞伴效应） |

### ⚠️ 批判性思考：为什么不能简单按频次选模型？

1. **问题本质决定模型**：问题一是逆向问题，不是预测问题，所以XGBoost虽然出现32次但不适用于问题一
2. **数据特征决定方法**：粉丝投票满足单纯形约束（和为1），狄利克雷分布是数学上的"天然匹配"
3. **美赛评分标准**：创新性要求模型与问题的深度契合，而非热门工具的堆砌
4. **可解释性权衡**：某些高精度模型（如深度学习）在本题中不适用，因为需要向制作方解释

---

## 一、问题一：粉丝投票估算模型

### 1.1 问题数学本质深度分析

#### 为什么这是逆向问题（Inverse Problem）而非预测问题？

| 对比维度 | 正向问题（Forward） | 逆向问题（Inverse） |
|----------|---------------------|---------------------|
| **已知量** | 输入（投票） | 输出（淘汰结果） |
| **求解量** | 输出（谁被淘汰） | 输入（投票分布） |
| **解的性质** | 唯一确定 | **不唯一**，需额外约束 |
| **类比** | 给定初始条件求轨迹 | 给定轨迹反推初始条件 |
| **学科应用** | 普通物理模拟 | CT成像、地震波反演、参数估计 |

**关键洞察**：传统机器学习（回归、分类）需要**有标签的训练数据**，但粉丝投票是**完全保密**的，我们没有任何真实投票作为标签！因此，监督学习在此问题上**根本不适用**。

#### 数据约束的数学结构

粉丝投票 F = (F₁, F₂, ..., Fₙ) 满足：
- **单纯形约束**：ΣFᵢ = 1, Fᵢ ≥ 0（所有投票占比之和为1）
- **淘汰约束**（百分比制S3-S27）：被淘汰者L的总分最低
  - 0.5·J_L + 0.5·F_L < 0.5·J_k + 0.5·F_k, ∀k ≠ L
- **淘汰约束**（排名制S1-S2, S28+）：被淘汰者L的总排名最差
  - Rank(J_L) + Rank(F_L) > Rank(J_k) + Rank(F_k), ∀k ≠ L

**几何直观**：可行解集是高维单纯形上被多个超平面切割后的**凸多面体**。

### 1.2 为什么选择这两个模型？（原理驱动）

| 模型 | 选择理由（原理层面） | 不选其他模型的理由 |
|------|----------------------|-------------------|
| **约束优化** | 直接处理不等式约束，在可行域内搜索最优解 | 回归模型无法处理"解必须满足淘汰结果"的硬约束 |
| **贝叶斯MCMC+狄利克雷** | 狄利克雷是单纯形上的共轭先验，数学结构天然匹配；MCMC能给出后验分布而非点估计 | 神经网络等黑箱模型无法量化不确定性，且缺乏可解释性 |

---

### 方案一（基础保分）：约束优化模型 + 先验正则化

#### 核心原理（深度解析）

**为什么约束优化是解决逆向问题的自然选择？**

逆向问题的核心挑战是**解不唯一**——满足淘汰结果的投票组合有无穷多种。约束优化通过引入**目标函数**（先验假设）在所有可行解中选择"最合理"的一个。

**物理类比**：就像给定物体的落点反推初始速度——有无穷多条轨迹都能到达同一落点，但我们选择"能量最小"的那条（最合理假设）。

**数学形式**：

```
最小化：  Σᵢ (Fᵢ - F̂ᵢ)²        # 投票尽量接近先验估计
约束条件：
  (1) ΣFᵢ = 1                   # 单纯形约束
  (2) Fᵢ ≥ 0, ∀i               # 非负约束  
  (3) Score(L) < Score(k), ∀k≠L # 淘汰约束
```

其中 F̂ᵢ = Jᵢ 是先验估计（假设观众倾向给高分选手投票）。

**为什么用二次目标函数？**
- 凸函数，保证全局最优
- 对应最大熵原则下的高斯先验
- cvxpy等求解器高效支持

#### 适配性分析（与数据特征对应）

| DWTS数据特征 | 约束优化如何适配 |
|--------------|------------------|
| 投票是连续比例 | 凸优化天然处理连续变量 |
| 每周选手数不同（4-13人） | 每周独立建模，约束维度自动调整 |
| 规则三阶段变迁 | 约束条件按Season切换（百分比制↔排名制） |
| 存在0分/N/A | 预处理剔除后不影响优化结构 |

#### 创新点（相对传统方法）

| 创新点 | 传统做法 | 本方案改进 | 实际价值 |
|--------|----------|------------|----------|
| **先验正则化** | 无目标函数，任意可行解 | 引入 F̂=J 作为先验 | 避免"观众全投最弱者"等不合理解 |
| **松弛变量处理异常周** | 约束冲突则模型失败 | 添加松弛变量 ε | 识别争议周（如评委拯救干预） |
| **Bootstrap置信区间** | 仅输出点估计 | 对评委分加噪声多次求解 | 间接量化不确定性 |

#### 局限性与规避方案

| 局限性 | 根本原因 | 规避方案 |
|--------|----------|----------|
| 解不唯一 | 逆向问题固有性质 | 先验正则化缩小解空间 + 敏感性分析 |
| 排名制约束非凸 | 排名是离散操作 | 连续松弛：用softmax近似argmax |
| 无法直接给出概率分布 | 优化输出点估计 | 方案二补充概率推断 |

#### 可视化流程图

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    约束优化模型：从数据到投票估算                             │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌──────────────────┐                                                       │
│  │   原始数据输入    │                                                       │
│  │ ────────────────│                                                       │
│  │ • 评委分 J_{i,t} │                                                       │
│  │ • 淘汰者 L_t     │                                                       │
│  │ • 季节规则标记   │                                                       │
│  └────────┬─────────┘                                                       │
│           │                                                                 │
│           ▼                                                                 │
│  ┌──────────────────┐     ┌──────────────────┐                             │
│  │  数据预处理       │────►│   约束构建        │                             │
│  │ ────────────────│     │ ────────────────│                             │
│  │ • 剔除0分/N/A    │     │ • S1-2,S28+:    │                             │
│  │ • 归一化评委分   │     │   排名制约束     │                             │
│  │ • 识别评委人数   │     │ • S3-S27:       │                             │
│  │   (3人/4人)      │     │   百分比制约束   │                             │
│  └──────────────────┘     └────────┬─────────┘                             │
│                                    │                                        │
│                                    ▼                                        │
│  ┌───────────────────────────────────────────────────────┐                 │
│  │                   优化问题求解                          │                 │
│  │  ┌─────────────────────────────────────────────────┐  │                 │
│  │  │ min Σ(Fᵢ - Jᵢ)²                                 │  │                 │
│  │  │ s.t. ΣFᵢ = 1, Fᵢ ≥ 0                           │  │                 │
│  │  │      淘汰约束（按规则）                          │  │                 │
│  │  └─────────────────────────────────────────────────┘  │                 │
│  │                         │                              │                 │
│  │                         ▼                              │                 │
│  │  ┌─────────────────────────────────────────────────┐  │                 │
│  │  │          cvxpy + ECOS求解器                      │  │                 │
│  │  └─────────────────────────────────────────────────┘  │                 │
│  └───────────────────────────────────────────────────────┘                 │
│                                    │                                        │
│                    ┌───────────────┼───────────────┐                        │
│                    ▼               ▼               ▼                        │
│           ┌─────────────┐  ┌─────────────┐  ┌─────────────┐                │
│           │  有可行解   │  │  无可行解   │  │ Bootstrap   │                │
│           │ ──────────│  │ ──────────│  │  采样       │                │
│           │ 输出F*估计  │  │ 添加松弛变量│  │ ──────────│                │
│           │ 验证一致性  │  │ 标记异常周  │  │ 多次求解   │                │
│           └─────────────┘  └─────────────┘  │ 估计置信区间│                │
│                                             └─────────────┘                │
│                                                                             │
│  ┌─────────────────────────────────────────────────────────────┐           │
│  │                        输出物                                │           │
│  │  • 粉丝投票估计矩阵 F*[选手×周]                              │           │
│  │  • 一致性验证报告（预测淘汰 vs 实际淘汰 准确率）             │           │
│  │  • 松弛变量报告（识别评委拯救等干预周）                      │           │
│  │  • Bootstrap置信区间（95% CI）                               │           │
│  └─────────────────────────────────────────────────────────────┘           │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

### 方案二（创新冲奖）：贝叶斯推断 + 狄利克雷先验 + 拒绝采样

#### 核心原理（深度解析）

**为什么贝叶斯方法是量化不确定性的"正统"选择？**

题目明确要求评估估计的**确定性（Certainty）**。约束优化只能给出一个点估计，而贝叶斯方法直接输出**后验概率分布**——这是回答"我们有多确定"的数学最优框架。

**为什么狄利克雷分布是"天然匹配"的先验？**

| 数学性质 | 与投票估算的对应 |
|----------|------------------|
| 定义域是单纯形 | 投票占比天然满足 ΣFᵢ=1, Fᵢ≥0 |
| 是Categorical分布的共轭先验 | 后验仍是狄利克雷，计算方便 |
| 参数α控制"信息量" | α=1为无信息先验，α=J·N为信息先验 |
| 支持稀疏/集中分布 | 可建模"投票集中于少数选手"的场景 |

**贝叶斯推断框架**：

```
先验：     F ~ Dirichlet(α)           # 投票的先验分布
似然：     P(E|J,F) = 𝟙{淘汰约束满足}  # 指示函数
后验：     P(F|J,E) ∝ P(E|J,F) · P(F) # 贝叶斯公式
```

**拒绝采样算法**：
1. 从先验 Dirichlet(α) 中采样一个候选 F
2. 检验该 F 是否满足淘汰约束
3. 若满足则接受，否则拒绝
4. 重复直到获得足够有效样本
5. 有效样本的统计量即为后验估计

#### 为什么用拒绝采样而非标准MCMC？

| 方法 | 优点 | 缺点 | 本题适用性 |
|------|------|------|------------|
| **拒绝采样** | 实现简单，无需调参 | 高维时接受率低 | ✅ 本题每周最多13人，维度可控 |
| MCMC (MH) | 适用高维 | 需要proposal分布设计 | ⚠️ 可作为备选 |
| 变分推断 | 计算快 | 近似误差难控制 | ❌ 不推荐 |

#### 创新点（相对传统方法）

| 创新点 | 数学依据 | 实际价值 |
|--------|----------|----------|
| **香农熵度量确定性** | H(F) = -Σ P(Fᵢ) log P(Fᵢ) | 熵低=可行域窄=估计更确定 |
| **信息先验 vs 无信息先验对比** | α=1 vs α=J·N | 验证先验假设的合理性 |
| **逐选手不确定性分析** | 后验方差 Var(Fᵢ) | 识别"投票难以确定"的争议选手 |

#### 不确定性的信息论解释

**为什么用香农熵而非方差？**

- 方差：假设分布是高斯的（对称、单峰）
- 香农熵：对任意分布都有效，能捕捉多峰、偏斜等复杂结构
- 题目要求的"Certainty"对应的数学概念就是熵的倒数

**确定性度量公式**：

```
香农熵：    H(F) = -Σᵢ E[Fᵢ] log E[Fᵢ]
确定性指数：C = 1 / (1 + H(F))    # 归一化到[0,1]
```

#### 可视化流程图

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                 贝叶斯推断：从数据到后验分布                                  │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌──────────────────┐     ┌──────────────────┐                             │
│  │   先验设计        │     │   似然函数构建    │                             │
│  │ ────────────────│     │ ────────────────│                             │
│  │ 无信息: α=1     │     │ P(E|J,F) =       │                             │
│  │ 信息: α=J·N     │     │   𝟙{F满足淘汰约束}│                             │
│  └────────┬─────────┘     └────────┬─────────┘                             │
│           │                        │                                        │
│           └──────────┬─────────────┘                                        │
│                      ▼                                                      │
│  ┌───────────────────────────────────────────────────────┐                 │
│  │                 拒绝采样算法                            │                 │
│  │  ┌─────────────────────────────────────────────────┐  │                 │
│  │  │ for trial in range(50000):                      │  │                 │
│  │  │     F_candidate = np.random.dirichlet(α)        │  │                 │
│  │  │     if satisfies_elimination_constraint(F, J, L):│  │                 │
│  │  │         valid_samples.append(F_candidate)       │  │                 │
│  │  └─────────────────────────────────────────────────┘  │                 │
│  │                         │                              │                 │
│  │                         ▼                              │                 │
│  │  ┌─────────────────────────────────────────────────┐  │                 │
│  │  │   接受率诊断：有效样本数 / 总采样数             │  │                 │
│  │  │   • 接受率 > 1%：采样充分                        │  │                 │
│  │  │   • 接受率 < 0.1%：考虑增加采样或调整先验       │  │                 │
│  │  └─────────────────────────────────────────────────┘  │                 │
│  └───────────────────────────────────────────────────────┘                 │
│                      │                                                      │
│                      ▼                                                      │
│  ┌───────────────────────────────────────────────────────┐                 │
│  │                 后验统计量提取                          │                 │
│  │                                                       │                 │
│  │   后验均值：  E[Fᵢ] = mean(valid_samples[:, i])       │                 │
│  │   后验标准差：Std[Fᵢ] = std(valid_samples[:, i])      │                 │
│  │   95%置信区间：[percentile(2.5%), percentile(97.5%)]  │                 │
│  │   香农熵：    H = -Σ E[Fᵢ] log E[Fᵢ]                  │                 │
│  └───────────────────────────────────────────────────────┘                 │
│                      │                                                      │
│                      ▼                                                      │
│  ┌─────────────────────────────────────────────────────────────┐           │
│  │                        输出物                                │           │
│  │  • 后验均值矩阵 E[F][选手×周]（点估计）                      │           │
│  │  • 后验标准差矩阵 Std[F][选手×周]（不确定性度量）            │           │
│  │  • 香农熵向量 H[周]（确定性指数）                            │           │
│  │  • 后验分布可视化（小提琴图/密度图）                         │           │
│  └─────────────────────────────────────────────────────────────┘           │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 二、问题二：投票方法比较模型

### 2.1 问题数学本质深度分析

#### 为什么这是反事实推演问题而非简单统计？

| 对比维度 | 简单统计 | 反事实推演（本题） |
|----------|----------|-------------------|
| **研究问题** | "两组数据有差异吗？" | "如果改变规则，结果会怎样？" |
| **数据来源** | 两组独立样本 | 同一组数据，不同处理 |
| **因果性** | 相关关系 | **因果关系**（规则→结果） |
| **方法论** | t检验、ANOVA | 控制变量实验、因果推断 |

**关键洞察**：问题二要回答的是"两种方法更偏向哪一方"——这是**因果问题**，不是描述性统计问题。我们需要构造"平行宇宙"：保持粉丝投票不变，观察不同规则下的淘汰结果。

#### 两种规则的数学本质差异

**信号处理视角**（参考资料创新点）：

| 特性 | 排名制 | 百分比制 |
|------|--------|----------|
| **数学本质** | 低通滤波器 | 线性放大器 |
| **保留信息** | 仅序数（相对位置） | 完整数值（绝对差距） |
| **对极端值** | **压缩**（99% vs 1% → 排名仅差1） | **放大**（差距直接体现在总分） |
| **实际效果** | 保护评委话语权 | 粉丝投票可"逆天改命" |

**举例说明**：
- 评委分：A=9, B=8, C=5
- 排名制：A排1, B排2, C排3 → 差距被压缩为1
- 百分比制：A占41%, B占36%, C占23% → C需多18%投票才能追平A

### 2.2 为什么选择这两个模型？（原理驱动）

| 模型 | 选择理由（原理层面） | 不选其他模型的理由 |
|------|----------------------|-------------------|
| **反事实模拟+配对检验** | 直接回答"如果换规则会怎样"的因果问题 | 简单描述统计无法回答因果问题 |
| **Kendall τ系数+敏感性分析** | 非参数方法，不假设分布；传播投票估计的不确定性 | Pearson相关假设线性关系，不适用于排名数据 |

---

### 方案一（基础保分）：反事实模拟 + 配对检验

#### 核心原理（深度解析）

**反事实推演的逻辑**：
1. 取出问题一估算的投票 F̂
2. 对每一周，**保持F̂不变**
3. 分别应用两种规则计算淘汰者
4. 记录"淘汰者是否不同"
5. 统计不一致率，检验是否显著

**为什么"保持投票不变"是关键？**

这是**控制变量法**的核心——只改变"规则"这一个变量，其他变量（评委分、投票）都固定。这样，淘汰结果的差异**只能归因于规则差异**。

**数学形式**：

```
对于每周 t:
  原规则淘汰者：L_orig = argmin_i Score_orig(J_i, F̂_i)
  反事实淘汰者：L_cf = argmin_i Score_cf(J_i, F̂_i)
  差异指标：D_t = 𝟙[L_orig ≠ L_cf]

不一致率：Divergence = (1/T) Σ_t D_t
McNemar检验：判断不一致是否系统性偏向某一方
```

#### 创新点（相对传统方法）

| 创新点 | 数学依据 | 实际价值 |
|--------|----------|----------|
| **肯德尔τ系数** | τ = (一致对 - 不一致对) / 总对数 | 量化两种规则的排名相关性（非仅看淘汰者） |
| **偏向性指数** | Bias = corr(最终排名, 评委分) - corr(最终排名, 粉丝票) | 正值偏向评委，负值偏向粉丝 |
| **分层分析** | 按"评委分差距"分组 | 揭示"竞争激烈时"哪种方法差异更大 |

#### 可视化流程图

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                反事实推演：从估算投票到方法比较                               │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌──────────────────┐     ┌──────────────────┐                             │
│  │   数据准备        │     │   规则实现        │                             │
│  │ ────────────────│     │ ────────────────│                             │
│  │ • 问题一估算F̂    │     │ • 排名制公式      │                             │
│  │ • 评委分J        │     │ • 百分比制公式    │                             │
│  │ • 原始淘汰记录   │     │ • S28+评委拯救    │                             │
│  └────────┬─────────┘     └────────┬─────────┘                             │
│           │                        │                                        │
│           └──────────┬─────────────┘                                        │
│                      ▼                                                      │
│  ┌───────────────────────────────────────────────────────┐                 │
│  │                 逐周反事实计算                          │                 │
│  │  ┌─────────────────────────────────────────────────┐  │                 │
│  │  │ for season in S1-S34:                           │  │                 │
│  │  │     for week in weeks:                          │  │                 │
│  │  │         L_rank = calc_elimination_rank(J, F̂)   │  │                 │
│  │  │         L_percent = calc_elimination_pct(J, F̂) │  │                 │
│  │  │         record_difference(L_rank, L_percent)    │  │                 │
│  │  └─────────────────────────────────────────────────┘  │                 │
│  └───────────────────────────────────────────────────────┘                 │
│                      │                                                      │
│                      ▼                                                      │
│  ┌───────────────────────────────────────────────────────┐                 │
│  │                 统计检验与量化                          │                 │
│  │                                                       │                 │
│  │   • 不一致率：Divergence = 不同淘汰周数 / 总周数       │                 │
│  │   • McNemar检验：p值判断差异是否显著                   │                 │
│  │   • Kendall τ：两种规则排名的相关系数                  │                 │
│  │   • 偏向性指数：正=偏评委，负=偏粉丝                   │                 │
│  └───────────────────────────────────────────────────────┘                 │
│                      │                                                      │
│                      ▼                                                      │
│  ┌─────────────────────────────────────────────────────────────┐           │
│  │                        输出物                                │           │
│  │  • 不一致率统计表（按季节/规则阶段分组）                     │           │
│  │  • 争议周列表（两种规则淘汰不同选手的周）                    │           │
│  │  • 偏向性可视化（热力图显示各季节的偏向程度）                │           │
│  │  • Kendall τ系数矩阵                                        │           │
│  └─────────────────────────────────────────────────────────────┘           │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

### 方案二（创新冲奖）：因果推断框架 + Bootstrap敏感性分析

#### 核心原理（深度解析）

**为什么需要敏感性分析？**

问题一的投票估算不是"真值"，而是有不确定性的估计。如果投票估计稍有变化，方法比较的结论会改变吗？敏感性分析回答这个问题。

**Bootstrap传播不确定性**：
1. 对问题一的有效样本池进行重采样
2. 每次重采样后重新做反事实分析
3. 获得不一致率的**分布**而非单一值
4. 若95% CI不包含0，则结论稳健

#### 创新点（相对传统方法）

| 创新点 | 数学依据 | 实际价值 |
|--------|----------|----------|
| **不确定性传播** | Bootstrap重采样 | 结论附带置信区间，更可信 |
| **争议案例深度分析** | 提取Bobby Bones, Jerry Rice等 | 具体案例增强说服力 |
| **"民粹抑制度"指标** | 定义为：排名制下技术差者的淘汰提前程度 | 新指标量化"公平性" |

---

## 三、问题三：影响因素分析模型

### 3.1 问题数学本质深度分析

#### 为什么这是归因分析而非预测问题？

| 对比维度 | 预测问题 | 归因分析（本题） |
|----------|----------|------------------|
| **目标** | 尽可能准确预测Y | 找出X如何影响Y |
| **评估指标** | RMSE、准确率 | **系数显著性、可解释性** |
| **模型选择** | 精度优先 | **可解释性优先** |
| **典型模型** | 神经网络、集成学习 | 回归模型、因果推断 |

**关键洞察**：题目要求"分析影响"，不是"预测结果"。我们需要回答"年龄增加1岁，评委分会变化多少？"这是**因果系数**问题。

#### 数据结构的特殊性

**为什么必须考虑舞伴效应？**

| 特征 | 明星 | 舞伴 |
|------|------|------|
| 出现次数 | 1次 | **多次**（如Derek Hough出场17季） |
| 统计处理 | 固定效应 | **随机效应** |
| 影响路径 | 直接影响 | 可能"带飞"队友 |

舞伴是**面板数据中的聚类变量**——同一舞伴下的观测不独立。忽略这一点会导致标准误低估、假阳性。

### 3.2 为什么选择这两个模型？（原理驱动）

| 模型 | 选择理由（原理层面） | 不选其他模型的理由 |
|------|----------------------|-------------------|
| **混合效应模型（LMEM）** | 正确处理舞伴的重复测量结构；系数直接可解释 | 普通线性回归忽略聚类，标准误错误 |
| **XGBoost + SHAP** | 捕捉非线性、交互效应；SHAP提供因果层面解释 | 随机森林特征重要性是"相关性"非"因果性" |

---

### 方案一（基础保分）：线性混合效应模型（LMEM）

#### 核心原理（深度解析）

**混合效应模型的数学形式**：

```
Y_ij = β₀ + β₁·Age_ij + β₂·Industry_ij + u_partner_j + ε_ij

其中：
- i: 第i位选手
- j: 第j位舞伴
- β: 固定效应（我们关心的系数）
- u_partner_j ~ N(0, σ²_u): 随机效应（舞伴特有的"加成"）
- ε_ij ~ N(0, σ²): 残差
```

**为什么舞伴是随机效应而非固定效应？**

| 效应类型 | 适用情况 | 本题舞伴 |
|----------|----------|----------|
| 固定效应 | 研究对象本身感兴趣 | ❌ 我们不关心"Derek Hough具体加成多少" |
| 随机效应 | 作为抽样自某总体的代表 | ✅ 舞伴是"职业舞者群体"的样本 |

**实际价值**：混合效应模型让我们能**分离**明星特征的影响和舞伴的影响，得到更准确的系数估计。

#### 创新点（相对传统方法）

| 创新点 | 数学依据 | 实际价值 |
|--------|----------|----------|
| **双模型对比** | 分别拟合Y=评委分和Y=估算投票 | 回答"评委和粉丝看重的因素相同吗？" |
| **交互项引入** | Age × Industry | 检验"年龄对不同行业选手影响不同" |
| **组内相关系数ICC** | ICC = σ²_u / (σ²_u + σ²) | 量化"舞伴效应解释了多少变异" |

#### 可视化流程图

```
┌─────────────────────────────────────────────────────────────────────────────┐
│              混合效应模型：从数据到影响因素量化                               │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌──────────────────┐     ┌──────────────────┐                             │
│  │   特征矩阵构建    │     │   响应变量设定    │                             │
│  │ ────────────────│     │ ────────────────│                             │
│  │ • Age（连续）    │     │ • Y1 = 评委平均分 │                             │
│  │ • Industry（分类）│     │ • Y2 = 估算投票占比│                             │
│  │ • Gender（二元） │     │                   │                             │
│  │ • Season（控制） │     │ ← 两个模型分别拟合 │                             │
│  └────────┬─────────┘     └────────┬─────────┘                             │
│           │                        │                                        │
│           └──────────┬─────────────┘                                        │
│                      ▼                                                      │
│  ┌───────────────────────────────────────────────────────┐                 │
│  │              混合效应模型拟合                           │                 │
│  │                                                       │                 │
│  │   model_judge = smf.mixedlm("judge_score ~ age +     │                 │
│  │                   C(industry) + C(gender)",           │                 │
│  │                   data=df, groups=df["partner"])      │                 │
│  │                                                       │                 │
│  │   model_vote = smf.mixedlm("estimated_vote ~ age +   │                 │
│  │                  C(industry) + C(gender)",            │                 │
│  │                  data=df, groups=df["partner"])       │                 │
│  └───────────────────────────────────────────────────────┘                 │
│                      │                                                      │
│                      ▼                                                      │
│  ┌───────────────────────────────────────────────────────┐                 │
│  │                 结果解读                                │                 │
│  │                                                       │                 │
│  │   固定效应系数表：                                     │                 │
│  │   ┌────────────┬─────────┬─────────┬────────┐        │                 │
│  │   │ 变量       │ β_judge │ β_vote  │ 差异   │        │                 │
│  │   ├────────────┼─────────┼─────────┼────────┤        │                 │
│  │   │ Age        │ +0.05*  │ -0.02   │ 相反   │        │                 │
│  │   │ Athlete    │ +0.8**  │ +1.2**  │ 同向   │        │                 │
│  │   │ ...        │         │         │        │        │                 │
│  │   └────────────┴─────────┴─────────┴────────┘        │                 │
│  │                                                       │                 │
│  │   ICC（组内相关系数）：舞伴效应解释了X%的变异          │                 │
│  └───────────────────────────────────────────────────────┘                 │
│                      │                                                      │
│                      ▼                                                      │
│  ┌─────────────────────────────────────────────────────────────┐           │
│  │                        输出物                                │           │
│  │  • 固定效应系数表（含置信区间、p值）                         │           │
│  │  • 随机效应方差分量（舞伴效应大小）                          │           │
│  │  • 系数森林图（可视化比较评委vs粉丝的影响差异）              │           │
│  │  • ICC报告（舞伴效应占比）                                   │           │
│  └─────────────────────────────────────────────────────────────┘           │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

### 方案二（创新冲奖）：XGBoost + SHAP可解释性分析

#### 核心原理（深度解析）

**为什么在"可解释性优先"的问题中用XGBoost？**

传统观点认为XGBoost是"黑箱"，但**SHAP（SHapley Additive exPlanations）**彻底改变了这一点。SHAP基于博弈论中的Shapley值，将模型预测**精确分解**为各特征的贡献。

**Shapley值的数学性质**：

```
对于样本i的预测值ŷᵢ：
ŷᵢ = φ₀ + Σⱼ φᵢⱼ

其中：
- φ₀: 基准值（所有样本的平均预测）
- φᵢⱼ: 特征j对样本i预测的贡献

关键性质：
- 加和性：所有特征贡献之和 = 预测值 - 基准值
- 局部准确性：对每个样本都精确成立
- 一致性：特征贡献越大，Shapley值越大
```

**为什么SHAP比传统特征重要性更好？**

| 指标 | 传统特征重要性 | SHAP值 |
|------|---------------|--------|
| 含义 | 特征被使用的频次 | 特征对预测的**因果贡献** |
| 方向 | 只有大小，无方向 | **有正负方向** |
| 样本级 | 全局平均 | **每个样本都有** |
| 交互效应 | 无法展示 | SHAP交互值可计算 |

#### 创新点（相对传统方法）

| 创新点 | 数学依据 | 实际价值 |
|--------|----------|----------|
| **SHAP蜂群图** | 按特征值着色的SHAP分布 | 直观展示"什么样的特征值导致什么影响" |
| **SHAP交互值** | φᵢⱼₖ = Shapley交互 | 揭示"年轻运动员 vs 年轻演员"的差异 |
| **SHAP依赖图** | SHAP值 vs 特征值散点图 | 发现非线性关系（如年龄的最优区间） |

#### 可视化流程图

```
┌─────────────────────────────────────────────────────────────────────────────┐
│              XGBoost + SHAP：从黑箱到可解释                                  │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌──────────────────┐     ┌──────────────────┐                             │
│  │   特征工程        │     │   模型训练        │                             │
│  │ ────────────────│     │ ────────────────│                             │
│  │ • One-hot编码    │     │ • XGBRegressor   │                             │
│  │   (Industry)     │     │ • 5折交叉验证    │                             │
│  │ • 舞伴编码       │     │ • 早停防过拟合   │                             │
│  │ • 赛季趋势       │     │                   │                             │
│  └────────┬─────────┘     └────────┬─────────┘                             │
│           │                        │                                        │
│           └──────────┬─────────────┘                                        │
│                      ▼                                                      │
│  ┌───────────────────────────────────────────────────────┐                 │
│  │              SHAP值计算                                │                 │
│  │                                                       │                 │
│  │   explainer = shap.TreeExplainer(model)              │                 │
│  │   shap_values = explainer(X)                         │                 │
│  │                                                       │                 │
│  │   # 三种关键可视化                                     │                 │
│  │   shap.summary_plot(shap_values, X)      # 蜂群图     │                 │
│  │   shap.dependence_plot("age", shap_values, X) # 依赖图│                 │
│  │   shap.interaction_values(...)            # 交互图   │                 │
│  └───────────────────────────────────────────────────────┘                 │
│                      │                                                      │
│                      ▼                                                      │
│  ┌───────────────────────────────────────────────────────┐                 │
│  │              SHAP蜂群图解读示例                         │                 │
│  │                                                       │                 │
│  │   Age        ●●●●●●●●●●|●●●●●●●●●●                    │                 │
│  │              蓝(年轻)    红(年长)                      │                 │
│  │              ────────────────────────                │                 │
│  │              负影响      正影响                        │                 │
│  │                                                       │                 │
│  │   解读：红点（年长）在正侧 → 年龄大有助于评委分        │                 │
│  │         蓝点（年轻）在负侧 → 年龄小降低评委分          │                 │
│  └───────────────────────────────────────────────────────┘                 │
│                      │                                                      │
│                      ▼                                                      │
│  ┌─────────────────────────────────────────────────────────────┐           │
│  │                        输出物                                │           │
│  │  • SHAP蜂群图（全局特征重要性+方向）                         │           │
│  │  • SHAP依赖图（单特征的非线性效应）                          │           │
│  │  • SHAP交互图（特征交互效应）                                │           │
│  │  • 样本级SHAP瀑布图（解释单个预测）                          │           │
│  └─────────────────────────────────────────────────────────────┘           │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 四、问题四：新投票系统设计模型

### 4.1 问题数学本质深度分析

#### 为什么这是多目标优化问题而非单目标？

**阿罗不可能定理的启示**：社会选择理论证明，**没有完美的投票系统**能同时满足所有合理标准。本题中，"公平性"（技术好的赢）和"娱乐性"（观众喜欢的赢）本质上是**矛盾**的。

| 目标 | 极端情况 | 问题 |
|------|----------|------|
| 完全公平 | 只看评委分 | 观众参与感为零，收视率下降 |
| 完全娱乐 | 只看粉丝票 | 技术最差者可能夺冠，专业性受质疑 |

**数学建模**：将问题转化为多目标优化，寻找**帕累托前沿**——所有"无法在不牺牲一个目标的情况下改进另一个目标"的解集。

#### 三个核心目标的数学定义

```
f₁(专业性) = corr(最终排名, 评委排名)          # 越大越好
f₂(民意性) = corr(最终排名, 粉丝投票排名)      # 越大越好
f₃(悬念性) = mean(逐周结果的信息熵)            # 越大越好（不可预测）
```

### 4.2 为什么选择这两个模型？（原理驱动）

| 模型 | 选择理由（原理层面） | 不选其他模型的理由 |
|------|----------------------|-------------------|
| **动态权重+网格搜索** | 简单、透明、可解释；符合节目实际需求 | 复杂优化可能产生"理论最优但实际不可行"的方案 |
| **NSGA-II多目标优化** | 能找到完整的帕累托前沿，供决策者选择 | 单目标优化只能给一个解，无法展示权衡 |

---

### 方案一（基础保分）：动态权重系统 + 网格搜索

#### 核心原理（深度解析）

**为什么"动态权重"比"静态50/50"更好？**

现行百分比制的问题是**一刀切**——初期和决赛用相同权重，但：
- **初期**：淘汰的都是明显弱者，让粉丝决定无伤大雅
- **后期**：剩下的都是强者，需要专业眼光区分高下

**动态权重公式**：

```
S_total(t) = w(t) · S_judge + (1 - w(t)) · S_fan

其中 t = 当前周次 / 总周次（赛季进度，0到1）

权重函数设计：
w(t) = w_start + (w_end - w_start) · t

例如：w_start = 0.3, w_end = 0.7
→ 初期30%评委+70%粉丝，后期70%评委+30%粉丝
```

**网格搜索优化**：
- 遍历 w_start ∈ [0.2, 0.5]
- 遍历 w_end ∈ [0.5, 0.8]
- 计算每组参数下的f₁、f₂、f₃
- 选择综合得分最高的参数组合

#### 创新点（相对传统方法）

| 创新点 | 设计理由 | 实际价值 |
|--------|----------|----------|
| **Sigmoid权重曲线** | 平滑过渡，避免"权重突变"引发争议 | 观众不会感觉"突然被剥夺投票权" |
| **"复活权"机制** | 当粉丝投票将技术第一送入淘汰区时，评委可干预 | 兜底保护专业性，每季限用一次 |
| **历史模拟验证** | 用S1-S34数据测试新系统 | 证明新系统"如果历史上采用会怎样" |

#### 可视化流程图

```
┌─────────────────────────────────────────────────────────────────────────────┐
│              动态权重系统：从设计到验证                                       │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌──────────────────┐     ┌──────────────────┐                             │
│  │   参数空间定义    │     │   目标函数定义    │                             │
│  │ ────────────────│     │ ────────────────│                             │
│  │ • w_start ∈[0.2,0.5]│  │ • f₁ = 专业性    │                             │
│  │ • w_end ∈[0.5,0.8]  │  │ • f₂ = 民意性    │                             │
│  │ • 复活权使用条件   │   │ • f₃ = 悬念性    │                             │
│  └────────┬─────────┘     └────────┬─────────┘                             │
│           │                        │                                        │
│           └──────────┬─────────────┘                                        │
│                      ▼                                                      │
│  ┌───────────────────────────────────────────────────────┐                 │
│  │              历史模拟引擎                               │                 │
│  │                                                       │                 │
│  │   for w_start in grid:                                │                 │
│  │       for w_end in grid:                              │                 │
│  │           for season in S1-S34:                       │                 │
│  │               new_results = simulate(season, w_start, w_end)            │
│  │               f1 = calc_professionalism(new_results) │                 │
│  │               f2 = calc_popularity(new_results)       │                 │
│  │               f3 = calc_suspense(new_results)         │                 │
│  └───────────────────────────────────────────────────────┘                 │
│                      │                                                      │
│                      ▼                                                      │
│  ┌───────────────────────────────────────────────────────┐                 │
│  │              最优参数选择                               │                 │
│  │                                                       │                 │
│  │   综合得分 = 0.4·f₁ + 0.4·f₂ + 0.2·f₃               │                 │
│  │   （权重可调整，体现决策者偏好）                       │                 │
│  │                                                       │                 │
│  │   推荐方案：w_start=0.3, w_end=0.7                   │                 │
│  │   含义：初期粉丝主导，后期评委主导                     │                 │
│  └───────────────────────────────────────────────────────┘                 │
│                      │                                                      │
│                      ▼                                                      │
│  ┌─────────────────────────────────────────────────────────────┐           │
│  │                        输出物                                │           │
│  │  • 推荐参数组合及综合得分                                    │           │
│  │  • 新系统 vs 原系统的对比表（各目标值）                      │           │
│  │  • 历史模拟案例（如Bobby Bones在新系统下的命运）             │           │
│  │  • 参数敏感性热力图                                          │           │
│  └─────────────────────────────────────────────────────────────┘           │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

### 方案二（创新冲奖）：NSGA-II多目标优化 + 帕累托前沿

#### 核心原理（深度解析）

**为什么用NSGA-II而非加权求和？**

加权求和（如0.4·f₁ + 0.4·f₂ + 0.2·f₃）有两个问题：
1. 权重的选择是**主观的**，不同决策者可能有不同偏好
2. **无法发现非凸前沿**——某些权衡方案会被遗漏

NSGA-II（Non-dominated Sorting Genetic Algorithm II）能找到**完整的帕累托前沿**，让决策者根据自己的偏好选择。

**帕累托最优的定义**：
解A **帕累托优于** 解B，当且仅当：
- A在所有目标上不比B差
- A至少在一个目标上严格优于B

**帕累托前沿**：所有不被任何其他解帕累托优于的解的集合。

#### 创新点（相对传统方法）

| 创新点 | 数学依据 | 实际价值 |
|--------|----------|----------|
| **三目标优化** | 专业性、民意性、悬念性 | 全面权衡，不遗漏重要维度 |
| **帕累托前沿可视化** | 3D散点图/平行坐标图 | 直观展示所有"好"方案及其权衡 |
| **方案聚类** | K-means聚类帕累托解 | 归纳为"专业优先型""民意优先型""平衡型" |

#### 可视化流程图

```
┌─────────────────────────────────────────────────────────────────────────────┐
│              NSGA-II多目标优化：寻找帕累托前沿                                │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌──────────────────┐     ┌──────────────────┐                             │
│  │   决策变量定义    │     │   目标函数定义    │                             │
│  │ ────────────────│     │ ────────────────│                             │
│  │ • x₁: w_start   │     │ • f₁ = -专业性   │                             │
│  │ • x₂: w_end     │     │ • f₂ = -民意性   │（取负数，转为最小化）        │
│  │ • x₃: 复活权阈值│     │ • f₃ = -悬念性   │                             │
│  └────────┬─────────┘     └────────┬─────────┘                             │
│           │                        │                                        │
│           └──────────┬─────────────┘                                        │
│                      ▼                                                      │
│  ┌───────────────────────────────────────────────────────┐                 │
│  │              NSGA-II进化过程                            │                 │
│  │                                                       │                 │
│  │   from pymoo.algorithms.moo.nsga2 import NSGA2       │                 │
│  │   from pymoo.optimize import minimize                 │                 │
│  │                                                       │                 │
│  │   algorithm = NSGA2(pop_size=100)                    │                 │
│  │   result = minimize(problem, algorithm,               │                 │
│  │                     ('n_gen', 200), verbose=True)     │                 │
│  │                                                       │                 │
│  │   pareto_front = result.F  # 帕累托前沿               │                 │
│  │   pareto_solutions = result.X  # 对应的参数           │                 │
│  └───────────────────────────────────────────────────────┘                 │
│                      │                                                      │
│                      ▼                                                      │
│  ┌───────────────────────────────────────────────────────┐                 │
│  │              帕累托前沿可视化                           │                 │
│  │                                                       │                 │
│  │       f₁(专业性)                                      │                 │
│  │          ^                                            │                 │
│  │          │    ★ <-- 帕累托最优解                      │                 │
│  │          │  ★   ★                                     │                 │
│  │          │    ★   ★  ← "专业优先型"                  │                 │
│  │          │      ★   ★                                │                 │
│  │          │        ★  ← "平衡型"                       │                 │
│  │          │          ★  ← "民意优先型"                 │                 │
│  │          └──────────────► f₂(民意性)                  │                 │
│  │                                                       │                 │
│  └───────────────────────────────────────────────────────┘                 │
│                      │                                                      │
│                      ▼                                                      │
│  ┌─────────────────────────────────────────────────────────────┐           │
│  │                        输出物                                │           │
│  │  • 帕累托前沿3D可视化（交互式Plotly图）                      │           │
│  │  • 推荐方案列表（按类型分组：专业/民意/平衡）                │           │
│  │  • 各方案参数设置及目标值对比表                              │           │
│  │  • 给制作方的决策建议（根据节目定位选择）                    │           │
│  └─────────────────────────────────────────────────────────────┘           │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 五、模型选择总览表（基于原理分析）

| 小问 | 问题本质 | 方案一（基础保分） | 方案二（创新冲奖） | 选择依据 |
|------|----------|-------------------|-------------------|----------|
| **Q1: 投票估算** | 逆向问题 | 约束优化+先验正则化 | 贝叶斯+狄利克雷+拒绝采样 | 无标签数据→不能用监督学习；需量化不确定性→贝叶斯最优 |
| **Q2: 方法比较** | 反事实推演 | 控制变量模拟+配对检验 | Kendall τ+Bootstrap敏感性 | 因果问题→需控制变量；估计有不确定性→需传播 |
| **Q3: 影响分析** | 归因分析 | 混合效应模型 | XGBoost+SHAP | 舞伴重复出现→必须用随机效应；需可解释性→SHAP最优 |
| **Q4: 系统设计** | 多目标优化 | 动态权重+网格搜索 | NSGA-II+帕累托前沿 | 公平vs娱乐矛盾→无单一最优；需展示权衡→帕累托 |

---

## 六、模型实现技术栈

### 6.1 Python库推荐（按问题）

| 问题 | 基础方案 | 创新方案 |
|------|----------|----------|
| Q1 | cvxpy + ECOS | numpy (狄利克雷采样) |
| Q2 | scipy.stats (McNemar, Kendall) | - |
| Q3 | statsmodels (mixedlm) | xgboost + shap |
| Q4 | numpy (网格搜索) | pymoo (NSGA-II) |
| 可视化 | matplotlib, seaborn | plotly (交互式) |

### 6.2 关键代码片段

```python
# ===== 问题一：拒绝采样估算投票 =====
import numpy as np

def estimate_votes_rejection_sampling(judge_scores, elim_idx, n_trials=50000):
    """拒绝采样法估算粉丝投票后验分布"""
    N = len(judge_scores)
    j_norm = judge_scores / np.sum(judge_scores)
    valid_samples = []
    
    for _ in range(n_trials):
        # 从狄利克雷先验采样
        f_candidate = np.random.dirichlet(np.ones(N))
        # 计算总分（百分比制）
        total_score = 0.5 * j_norm + 0.5 * f_candidate
        # 检验淘汰约束
        if total_score[elim_idx] < np.min(np.delete(total_score, elim_idx)):
            valid_samples.append(f_candidate)
    
    if len(valid_samples) == 0:
        return None, None
    
    samples = np.array(valid_samples)
    return np.mean(samples, axis=0), np.std(samples, axis=0)

# ===== 问题三：混合效应模型 =====
import statsmodels.formula.api as smf

model_judge = smf.mixedlm(
    "judge_score ~ age + C(industry) + C(gender)", 
    data=df, 
    groups=df["partner"]
)
result_judge = model_judge.fit()
print(result_judge.summary())

model_vote = smf.mixedlm(
    "estimated_vote ~ age + C(industry) + C(gender)", 
    data=df, 
    groups=df["partner"]
)
result_vote = model_vote.fit()
print(result_vote.summary())

# ===== 问题四：NSGA-II多目标优化 =====
from pymoo.core.problem import ElementwiseProblem
from pymoo.algorithms.moo.nsga2 import NSGA2
from pymoo.optimize import minimize

class VotingSystemProblem(ElementwiseProblem):
    def __init__(self, historical_data):
        super().__init__(n_var=2, n_obj=3, xl=[0.2, 0.5], xu=[0.5, 0.8])
        self.data = historical_data
    
    def _evaluate(self, x, out, *args, **kwargs):
        w_start, w_end = x
        # 模拟并计算三个目标
        f1 = -self.calc_professionalism(w_start, w_end)  # 取负，转为最小化
        f2 = -self.calc_popularity(w_start, w_end)
        f3 = -self.calc_suspense(w_start, w_end)
        out["F"] = [f1, f2, f3]

problem = VotingSystemProblem(historical_data)
algorithm = NSGA2(pop_size=100)
result = minimize(problem, algorithm, ('n_gen', 200))
```

---

## 七、时间分配建议

| 模型任务 | 基础方案耗时 | 创新方案额外耗时 | 优先级建议 |
|----------|-------------|-----------------|-----------|
| Q1模型 | 6h | +8h | ⭐⭐⭐ 必做双方案（核心） |
| Q2模型 | 4h | +4h | ⭐⭐ 基础必做，创新可选 |
| Q3模型 | 4h | +6h | ⭐⭐ 建议双方案对比 |
| Q4模型 | 4h | +6h | ⭐ 时间紧只做基础 |
| **总计** | **18h** | **+24h** | 根据进度灵活调整 |

---

**文档版本**: 2.0 (基于原理深度分析优化版)  
**生成日期**: 2026-01-30  
**适用竞赛**: MCM 2026 Problem C  
**核心改进**: 
1. 每个模型选择都基于问题数学本质的原理分析
2. 明确说明"为什么选这个模型"和"为什么不选其他模型"
3. 批判性吸收参考资料，而非简单按频次统计
